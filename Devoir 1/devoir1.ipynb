{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kenlm\n",
    "import re\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "#PATH = r\"C:\\Users\\barka\\Desktop\\NLP\\Data\\\"\n",
    "PATH = r\"C:\\Users\\Louis\\Documents\\University\\Masters\\A23\\NLP\\Devoirs\\data\\hw1\\train\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "Nous avons lancé cette commande pour entraîner le modèle:\n",
    "\n",
    "```\n",
    "code!\n",
    "```\n",
    "\n",
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a. Model Stats\n",
    "\n",
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kenlm = kenlm.LanguageModel(r\"C:\\Users\\Louis\\Documents\\University\\Masters\\A23\\NLP\\model2G.arpa\")\n",
    "#model_lmppl = lmppl.LM(\"C:\\\\Users\\\\Louis\\\\Documents\\\\University\\\\Masters\\\\A23\\\\NLP\\\\model2G.arpa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(PATH, \"r\", encoding=\"utf-8\")\n",
    "\n",
    "sentences = f.readlines()[:1000]\n",
    "\n",
    "perplexities = []\n",
    "for sentence in sentences:\n",
    "    sentence_filtered = sentence.replace('\\n', '')\n",
    "    score = model_kenlm.perplexity(sentence_filtered)\n",
    "    perplexities.append(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     1000.000000\n",
       "mean       412.933038\n",
       "std       1026.208320\n",
       "min         28.735342\n",
       "25%        145.652765\n",
       "50%        227.562864\n",
       "75%        419.894973\n",
       "max      21411.129543\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perp_df = pd.Series(perplexities)\n",
    "\n",
    "perp_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b. Slices Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# c. Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# d. Small Questions\n",
    "\n",
    "### i - Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Louis\\AppData\\Local\\Temp\\ipykernel_4068\\506740737.py:2: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  all_slices = pd.Series()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0          The U.S. Centers for Disease Control and Preve...\n",
       "1          When Ms. Winfrey invited Suzanne Somers to sha...\n",
       "2          Elk calling -- a skill that hunters perfected ...\n",
       "3                                                   Don 't !\n",
       "4          Fish , ranked 98th in the world , fired 22 ace...\n",
       "                                 ...                        \n",
       "2471015     I think the reason Darren Aronofsky wanted to...\n",
       "2471016    We 've asked the police to help me trace where...\n",
       "2471017    Wild spending and family dysfunction are commo...\n",
       "2471018     Many customers keep asking about ' Rambo 4 ' ...\n",
       "2471019    Where Ubisoft and developer Gameloft really do...\n",
       "Length: 2471020, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate all files\n",
    "all_slices = pd.Series()\n",
    "for slice_path in glob.glob(PATH+\"\\*.txt\"):\n",
    "    slice_df = pd.read_table(slice_path, header=None)\n",
    "    slice_df = slice_df[0] # Make it a Series\n",
    "\n",
    "    all_slices = pd.concat([all_slices, slice_df])\n",
    "all_slices = all_slices.reset_index(drop=True)\n",
    "\n",
    "all_slices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii - Repeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count repeats\n",
    "sentence_counts = all_slices.value_counts()\n",
    "seen_3 = sentence_counts[sentence_counts>=3]\n",
    "seen_4 = sentence_counts[sentence_counts>=4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "American negotiator Watson said the Bush administration is planning probably four more meetings in the Major Economies series before a \" leaders ' meeting \" in mid-2008 presents a final outcome .    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seen_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seen_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii - Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of occurences per caracter lengths: \n",
      "20: 35\n",
      "120: 1\n"
     ]
    }
   ],
   "source": [
    "sentence_lengths = all_slices.str.len()\n",
    "sentence_lengths_counts = sentence_lengths.value_counts()\n",
    "length_20 = len(sentence_lengths_counts[sentence_lengths_counts==20])\n",
    "length_120 = len(sentence_lengths_counts[sentence_lengths_counts==120])\n",
    "\n",
    "print(f\"Number of occurences per caracter lengths: \\n20: {length_20}\\n120: {length_120}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iv - Max & min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shortest sentence length: 2\n",
      "Longest sentence length: 9572\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shortest sentence length: {sentence_lengths.min()}\\nLongest sentence length: {sentence_lengths.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v - Short sentence frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "less_21 = all_slices[sentence_lengths < 21]\n",
    "less_21_counts = less_21.value_counts()\n",
    "less_21_counts.head(100).to_csv(PATH+\"\\\\frequent_short_sentences.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vi - Word frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the    3751181\n",
       "of     1584635\n",
       "a      1501086\n",
       "and    1471456\n",
       "in     1347002\n",
       "s       650276\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate everything into a single string\n",
    "all_slices_str = \"\"\n",
    "\n",
    "pattern = r'[^\\w\\s]|[\\d]' # Regex to select punctuation and digits\n",
    "for slice_path in glob.glob(PATH+\"\\*.txt\"):\n",
    "    f = open(slice_path, \"r\", encoding=\"utf-8\")\n",
    "    slice_str = f.read()\n",
    "\n",
    "    # Replacing punctuation, digits and skip lines\n",
    "    slice_str = re.sub(\"\\n\", ' ', slice_str) # Skipline becomes space\n",
    "    slice_str = re.sub(pattern, '', slice_str).lower()  # Remove punctuation and digits, then put it in lowercase\n",
    "    \n",
    "    # Concatenating\n",
    "    all_slices_str = all_slices_str + slice_str\n",
    "\n",
    "# Split over the spaces, removing them and putting them into pandas\n",
    "words = all_slices_str.split(\" \")\n",
    "word_df = pd.Series(words)\n",
    "\n",
    "word_counts = word_df.value_counts()\n",
    "word_counts = word_counts.drop([\"\", \"continue\", \"to\"]) # Drop continue, to, and '' which caused me problems\n",
    "word_counts.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vii - First 10  words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " A version of this article appeared in print on March                   113\n",
       " The yield on the benchmark 10-year Treasury note , which               109\n",
       " A version of this article appeared in print on January                  77\n",
       " Enterprise computing , economics of technology , Microsoft , I.B.M.     69\n",
       " This entry was posted by Gwen Robinson on Wednesday ,                   64\n",
       "                                                                       ... \n",
       " Even though his land is only six miles from official                     1\n",
       " The policy was designed to control the country 's exploding              1\n",
       " Rogge urged China to respect its \" moral engagement \"                    1\n",
       " They also include zebra and quagga mussels , which have                  1\n",
       " Where Ubisoft and developer Gameloft really do pull through is           1\n",
       "Length: 2738435, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_starts = []\n",
    "\n",
    "pattern = r'[^\\w\\s]|[\\d]' # Regex to select punctuation and digits\n",
    "for slice_path in glob.glob(PATH+\"\\*.txt\"):\n",
    "    f = open(slice_path, \"r\", encoding=\"utf-8\")\n",
    "    slice_str = f.readlines()\n",
    "\n",
    "    for sentence in slice_str:\n",
    "        sentence = sentence.split(\" \")\n",
    "        first_10 = sentence[:10]\n",
    "        \n",
    "        first_10_str = \"\"\n",
    "        for word in first_10:\n",
    "            first_10_str = first_10_str + \" \" + word\n",
    "        sentence_starts.append(first_10_str)\n",
    "\n",
    "sentence_starts = pd.Series(sentence_starts)\n",
    "sentence_starts.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### viii - Maj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YORK    5512\n",
       "NATO    3133\n",
       "NASA    2238\n",
       "NYSE    1720\n",
       "AIDS    1437\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate everything into a single string\n",
    "all_slices_str = \"\"\n",
    "\n",
    "pattern = r'[^\\w\\s]|[\\d]' # Regex to select punctuation and digits\n",
    "for slice_path in glob.glob(PATH+\"\\*.txt\"):\n",
    "    f = open(slice_path, \"r\", encoding=\"utf-8\")\n",
    "    slice_str = f.read()\n",
    "\n",
    "    # Replacing punctuation, digits and skip lines\n",
    "    slice_str = re.sub(\"\\n\", ' ', slice_str) # Skipline becomes space\n",
    "    slice_str = re.sub(pattern, '', slice_str)  # Remove punctuation and digits\n",
    "        \n",
    "    # Concatenating\n",
    "    all_slices_str = all_slices_str + slice_str\n",
    "\n",
    "# Split over the spaces, removing them and putting them into pandas\n",
    "words = all_slices_str.split(\" \")\n",
    "word_df = pd.Series(words)\n",
    "\n",
    "word_df_upper = word_df[word_df.str.isupper()]\n",
    "word_df_upper_4 = word_df_upper[word_df_upper.str.len()==4]\n",
    "word_df_upper_4_counts = word_df_upper_4.value_counts()\n",
    "word_df_upper_4_counts.to_csv(PATH + r\"\\most_common_4maj_words.csv\")\n",
    "word_df_upper_4_counts.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
