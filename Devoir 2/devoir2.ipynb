{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Initialisation\n",
    "\n",
    "## 0.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import chardet\n",
    "import editdistance\n",
    "import jellyfish\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "DATA_PATH = r\"C:\\Users\\Louis\\Documents\\University\\Masters\\A23\\NLP\\Devoirs\\data\\hw2\"\n",
    "#DATA_PATH = r\"C:\\Users\\barka\\Desktop\\NLP\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_encoding(file_path):\n",
    "\n",
    "    with open(file_path, 'rb') as file:\n",
    "        rawdata = file.read()\n",
    "    result = chardet.detect(rawdata)\n",
    "    return result['encoding']\n",
    "\n",
    "def get_word_counter(file_path, encoding):\n",
    "    word_counter = Counter()\n",
    "\n",
    "    with open(file_path, 'r', encoding=encoding) as file:\n",
    "        for line in file:\n",
    "            \n",
    "            parts = line.split()\n",
    "            if len(parts) >= 2:\n",
    "                word = parts[1]\n",
    "                \n",
    "                word_counter[word.strip()] += 1\n",
    "\n",
    "    # Return the Counter containing word frequencies\n",
    "    return word_counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.3 Check data quality\n",
    "Make sure Python is reading the lines correctly. And it does!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1000 rows in the file. There should be 1000. Correct number? True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding : utf-8\n",
      "There are 201315 rows in the file. There should be 201 315. Correct number? True\n"
     ]
    }
   ],
   "source": [
    "# Check ypos\n",
    "typos_file = open(DATA_PATH + r\"\\typo-0.2.txt\")\n",
    "\n",
    "for i, row in enumerate(typos_file):\n",
    "    #print(row)\n",
    "    pass\n",
    "\n",
    "print(f\"There are {i+1} rows in the file. There should be 1000. Correct number? {i+1==1000}\")\n",
    "\n",
    "# Check vocabulary\n",
    "\n",
    "encoding = detect_encoding(DATA_PATH + r\"\\voc-1bwc.txt\") #check encoding\n",
    "print(f\"Encoding : {encoding}\")\n",
    "\n",
    "voc = open(DATA_PATH + r\"\\voc-1bwc.txt\", encoding=encoding)\n",
    "\n",
    "for i, row in enumerate(voc):\n",
    "    #print(row)\n",
    "    pass\n",
    "\n",
    "print(f\"There are {i+1} rows in the file. There should be 201 315. Correct number? {i+1==201315}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many words in the vocabulary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201315\n"
     ]
    }
   ],
   "source": [
    "vocab = get_word_counter(DATA_PATH + r\"\\voc-1bwc.txt\", encoding)\n",
    "print(len(vocab)) # just to verify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Implementing various distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Distance functions\n",
    "\n",
    "### 1.1.a - Edit distance \n",
    "Taken from the blog, edited to return any number of likely words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P(word, N=sum(vocab.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return vocab[word] / N\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    huh = candidates(word)\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in vocab)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.b -  Jaro distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaro_correction(word):\n",
    "    \n",
    "    max_distance = float('-inf')\n",
    "    max_word = \"\"\n",
    "    \n",
    "    for w in vocab :\n",
    "        \n",
    "        distance = jellyfish.jaro_similarity(word, w)\n",
    "        \n",
    "        if max_distance < distance :\n",
    "            \n",
    "            max_distance = distance\n",
    "            max_word = w\n",
    "    \n",
    "    return max_word, max_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.c -  Jaro-Winkler distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaro_winkler_correction(word):\n",
    "    max_distance = float('-inf')\n",
    "    max_word = \"\"\n",
    "    \n",
    "    for w in vocab :\n",
    "        \n",
    "        distance = jellyfish.jaro_winkler_similarity(word, w)\n",
    "        \n",
    "        if max_distance < distance :\n",
    "            \n",
    "            max_distance = distance\n",
    "            max_word = w\n",
    "    \n",
    "    return max_word, max_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.d Generic Distance function\n",
    "\n",
    "Works with any function that takes two words as an input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This function applies a generic function over an entire vocabulary to compare the distance between a given word\n",
    "and every word inside the vocabulary. It then returns the n_neighbors most similar words.\n",
    "\n",
    "Parameters:\n",
    "    word: The word to find neighbors to.\n",
    "    vocabulary: A list (or list-like) of the vocabulary.\n",
    "    func: The distance function to apply without arguments (without parentheses).\n",
    "    minimum: Do we want the minimum distance? Boolean. True by default, will yield the minimum distance. If False, the function will yield the maximum distance. \n",
    "    n_neighbors: The number of most similar words to return.\n",
    "\n",
    "Returns:\n",
    "    vocabulary.head: A dataframe containing the n_neighbors most similar words to the input word, with the distances. \n",
    "'''\n",
    "def generic_distance_correction(word, vocabulary, func, minimum = True, n_neighbors=1):\n",
    "    vocabulary = pd.DataFrame(vocabulary, columns=[\"words\"])\n",
    "\n",
    "    def calculateDistance(series_word):\n",
    "        return func(series_word, word)\n",
    "    \n",
    "    distances = vocabulary[\"words\"].apply(calculateDistance)\n",
    "    \n",
    "    vocabulary[\"distance\"] = distances\n",
    "\n",
    "    if minimum:\n",
    "        vocabulary = vocabulary.sort_values(\"distance\", ascending=True)\n",
    "    else: \n",
    "        vocabulary = vocabulary.sort_values(\"distance\", ascending=False)\n",
    "\n",
    "    return vocabulary.head(n_neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Testing the correction methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>177635</th>\n",
       "      <td>spewing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189762</th>\n",
       "      <td>spelling</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171215</th>\n",
       "      <td>sperling</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174478</th>\n",
       "      <td>smelling</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185401</th>\n",
       "      <td>spilling</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           words  distance\n",
       "177635   spewing         1\n",
       "189762  spelling         1\n",
       "171215  sperling         1\n",
       "174478  smelling         2\n",
       "185401  spilling         2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generic_distance_correction('speling', vocab.keys(), editdistance.eval, True, 5) #Edit distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>171215</th>\n",
       "      <td>sperling</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189762</th>\n",
       "      <td>spelling</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167278</th>\n",
       "      <td>spellings</td>\n",
       "      <td>0.925926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196330</th>\n",
       "      <td>sleeping</td>\n",
       "      <td>0.910714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126688</th>\n",
       "      <td>sapling</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            words  distance\n",
       "171215   sperling  0.958333\n",
       "189762   spelling  0.958333\n",
       "167278  spellings  0.925926\n",
       "196330   sleeping  0.910714\n",
       "126688    sapling  0.904762"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generic_distance_correction('speling', vocab.keys(), jellyfish.jaro_similarity, False, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>189762</th>\n",
       "      <td>spelling</td>\n",
       "      <td>0.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171215</th>\n",
       "      <td>sperling</td>\n",
       "      <td>0.970833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167278</th>\n",
       "      <td>spellings</td>\n",
       "      <td>0.955556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177635</th>\n",
       "      <td>spewing</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196330</th>\n",
       "      <td>sleeping</td>\n",
       "      <td>0.919643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            words  distance\n",
       "189762   spelling  0.975000\n",
       "171215   sperling  0.970833\n",
       "167278  spellings  0.955556\n",
       "177635    spewing  0.933333\n",
       "196330   sleeping  0.919643"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generic_distance_correction('speling', vocab.keys(), jellyfish.jaro_winkler_similarity, False, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sperling', 0.9583333333333334)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaro_correction('speling') #Jaro distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('spelling', 0.975)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaro_winkler_correction('speling') #Jaro-Winkler distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Running the correction methods on the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 - Get the typos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_PATH + r\"\\typo-0.2.txt\", \"r\", encoding=encoding) as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Regex\n",
    "typo_pattern = r'<typo orig=\"([^\"]+)\">([^<]+)</typo>'\n",
    "typos = re.findall(typo_pattern, text)\n",
    "typos = dict(typos)\n",
    "typo_df = pd.DataFrame()\n",
    "typo_df[\"Word\"] = typos.keys()\n",
    "typo_df[\"Typo\"] = typos.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 - Apply correction methods: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correction_df(path, typos, func, minimum = True, n_neighbors=1):\n",
    "\n",
    "    if os.path.isfile(path):\n",
    "        correction_df = pd.read_csv(path, index_col = 0)\n",
    "\n",
    "    else: \n",
    "        correction_df = pd.DataFrame()\n",
    "\n",
    "        for i, typo in tqdm(enumerate(typos.values()), desc=\"Correcting Typos\", total=len(typos)):\n",
    "            corrections = generic_distance_correction(typo, vocab.keys(), func, minimum, n_neighbors)  # Jaro distance\n",
    "            row = corrections[\"words\"].reset_index(drop=True)\n",
    "            row.name = i\n",
    "            correction_df = pd.concat([correction_df, row], axis=1)\n",
    "        correction_df = correction_df.transpose()\n",
    "\n",
    "        correction_df.to_csv(path)\n",
    "    \n",
    "    return correction_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Jaro**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Typo</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wealthy</td>\n",
       "      <td>wealtohy</td>\n",
       "      <td>wealthy</td>\n",
       "      <td>wealth</td>\n",
       "      <td>welty</td>\n",
       "      <td>healthy</td>\n",
       "      <td>watley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>afford</td>\n",
       "      <td>aford</td>\n",
       "      <td>alford</td>\n",
       "      <td>afford</td>\n",
       "      <td>axford</td>\n",
       "      <td>ford</td>\n",
       "      <td>watford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Catholic</td>\n",
       "      <td>CatholiaCtholic</td>\n",
       "      <td>athol</td>\n",
       "      <td>palaeolithic</td>\n",
       "      <td>pathological</td>\n",
       "      <td>alghaithi</td>\n",
       "      <td>toit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cousins</td>\n",
       "      <td>coxusins</td>\n",
       "      <td>cousins</td>\n",
       "      <td>cousin</td>\n",
       "      <td>compulsions</td>\n",
       "      <td>coursing</td>\n",
       "      <td>coxswain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>masks</td>\n",
       "      <td>mmasks</td>\n",
       "      <td>masks</td>\n",
       "      <td>mask</td>\n",
       "      <td>mass</td>\n",
       "      <td>asks</td>\n",
       "      <td>unmasks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>plummeted</td>\n",
       "      <td>plummete</td>\n",
       "      <td>plummeted</td>\n",
       "      <td>plummet</td>\n",
       "      <td>plummetted</td>\n",
       "      <td>plummets</td>\n",
       "      <td>lumme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>posts</td>\n",
       "      <td>psts</td>\n",
       "      <td>pests</td>\n",
       "      <td>posts</td>\n",
       "      <td>pasts</td>\n",
       "      <td>pst</td>\n",
       "      <td>psst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>defy</td>\n",
       "      <td>deefy</td>\n",
       "      <td>defy</td>\n",
       "      <td>deep-fry</td>\n",
       "      <td>beefy</td>\n",
       "      <td>dewey</td>\n",
       "      <td>dee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>translation</td>\n",
       "      <td>translatmion</td>\n",
       "      <td>translation</td>\n",
       "      <td>translations</td>\n",
       "      <td>translational</td>\n",
       "      <td>translating</td>\n",
       "      <td>transaction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>keep</td>\n",
       "      <td>kpeep</td>\n",
       "      <td>peep</td>\n",
       "      <td>keep</td>\n",
       "      <td>upkeep</td>\n",
       "      <td>kpe</td>\n",
       "      <td>peeps</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1601 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Word             Typo            0             1              2  \\\n",
       "0         wealthy         wealtohy      wealthy        wealth          welty   \n",
       "1          afford            aford       alford        afford         axford   \n",
       "2        Catholic  CatholiaCtholic        athol  palaeolithic   pathological   \n",
       "3         cousins         coxusins      cousins        cousin    compulsions   \n",
       "4           masks           mmasks        masks          mask           mass   \n",
       "...           ...              ...          ...           ...            ...   \n",
       "1596    plummeted         plummete    plummeted       plummet     plummetted   \n",
       "1597        posts             psts        pests         posts          pasts   \n",
       "1598         defy            deefy         defy      deep-fry          beefy   \n",
       "1599  translation     translatmion  translation  translations  translational   \n",
       "1600         keep            kpeep         peep          keep         upkeep   \n",
       "\n",
       "                3            4  \n",
       "0         healthy       watley  \n",
       "1            ford      watford  \n",
       "2       alghaithi         toit  \n",
       "3        coursing     coxswain  \n",
       "4            asks      unmasks  \n",
       "...           ...          ...  \n",
       "1596     plummets        lumme  \n",
       "1597          pst         psst  \n",
       "1598        dewey          dee  \n",
       "1599  translating  transaction  \n",
       "1600          kpe        peeps  \n",
       "\n",
       "[1601 rows x 7 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaro_correction_df = get_correction_df(DATA_PATH + \"\\jaro_correction_df.csv\", typos, jellyfish.jaro_similarity, False, 5)\n",
    "\n",
    "jaro_typo_df = pd.concat([typo_df, jaro_correction_df], axis=1)\n",
    "jaro_typo_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jaro-Winkler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Correcting Typos:  12%|█▏        | 196/1601 [00:47<05:54,  3.97it/s]"
     ]
    }
   ],
   "source": [
    "jw_correction_df = get_correction_df(DATA_PATH + \"\\jw_correction_df.csv\", typos, jellyfish.jaro_winkler_similarity, False, 5)\n",
    "\n",
    "jw_typo_df = pd.concat([typo_df, jw_correction_df], axis=1)\n",
    "jw_typo_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Edit Distance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Typo</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>Typo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wealthy</td>\n",
       "      <td>wealtohy</td>\n",
       "      <td>wealthy</td>\n",
       "      <td>wealth</td>\n",
       "      <td>weal</td>\n",
       "      <td>wealthtv</td>\n",
       "      <td>welty</td>\n",
       "      <td>wealtohy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>afford</td>\n",
       "      <td>aford</td>\n",
       "      <td>afford</td>\n",
       "      <td>axford</td>\n",
       "      <td>alford</td>\n",
       "      <td>ford</td>\n",
       "      <td>affords</td>\n",
       "      <td>aford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Catholic</td>\n",
       "      <td>CatholiaCtholic</td>\n",
       "      <td>athol</td>\n",
       "      <td>palaeolithic</td>\n",
       "      <td>pathological</td>\n",
       "      <td>alghaithi</td>\n",
       "      <td>toit</td>\n",
       "      <td>CatholiaCtholic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cousins</td>\n",
       "      <td>coxusins</td>\n",
       "      <td>cousins</td>\n",
       "      <td>cousin</td>\n",
       "      <td>coxswain</td>\n",
       "      <td>compulsions</td>\n",
       "      <td>coun</td>\n",
       "      <td>coxusins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>masks</td>\n",
       "      <td>mmasks</td>\n",
       "      <td>masks</td>\n",
       "      <td>mask</td>\n",
       "      <td>mass</td>\n",
       "      <td>asks</td>\n",
       "      <td>mma</td>\n",
       "      <td>mmasks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>plummeted</td>\n",
       "      <td>plummete</td>\n",
       "      <td>plummeted</td>\n",
       "      <td>plummet</td>\n",
       "      <td>plummetted</td>\n",
       "      <td>plummets</td>\n",
       "      <td>plume</td>\n",
       "      <td>plummete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>posts</td>\n",
       "      <td>psts</td>\n",
       "      <td>pst</td>\n",
       "      <td>pests</td>\n",
       "      <td>pasts</td>\n",
       "      <td>posts</td>\n",
       "      <td>psst</td>\n",
       "      <td>psts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>defy</td>\n",
       "      <td>deefy</td>\n",
       "      <td>defy</td>\n",
       "      <td>deep-fry</td>\n",
       "      <td>deery</td>\n",
       "      <td>dee</td>\n",
       "      <td>deeny</td>\n",
       "      <td>deefy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>translation</td>\n",
       "      <td>translatmion</td>\n",
       "      <td>translation</td>\n",
       "      <td>translations</td>\n",
       "      <td>translational</td>\n",
       "      <td>translating</td>\n",
       "      <td>transaction</td>\n",
       "      <td>translatmion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>keep</td>\n",
       "      <td>kpeep</td>\n",
       "      <td>keep</td>\n",
       "      <td>peep</td>\n",
       "      <td>kpe</td>\n",
       "      <td>keeps</td>\n",
       "      <td>kee</td>\n",
       "      <td>kpeep</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1601 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Word             Typo            0             1              2  \\\n",
       "0         wealthy         wealtohy      wealthy        wealth           weal   \n",
       "1          afford            aford       afford        axford         alford   \n",
       "2        Catholic  CatholiaCtholic        athol  palaeolithic   pathological   \n",
       "3         cousins         coxusins      cousins        cousin       coxswain   \n",
       "4           masks           mmasks        masks          mask           mass   \n",
       "...           ...              ...          ...           ...            ...   \n",
       "1596    plummeted         plummete    plummeted       plummet     plummetted   \n",
       "1597        posts             psts          pst         pests          pasts   \n",
       "1598         defy            deefy         defy      deep-fry          deery   \n",
       "1599  translation     translatmion  translation  translations  translational   \n",
       "1600         keep            kpeep         keep          peep            kpe   \n",
       "\n",
       "                3            4             Typo  \n",
       "0        wealthtv        welty         wealtohy  \n",
       "1            ford      affords            aford  \n",
       "2       alghaithi         toit  CatholiaCtholic  \n",
       "3     compulsions         coun         coxusins  \n",
       "4            asks          mma           mmasks  \n",
       "...           ...          ...              ...  \n",
       "1596     plummets        plume         plummete  \n",
       "1597        posts         psst             psts  \n",
       "1598          dee        deeny            deefy  \n",
       "1599  translating  transaction     translatmion  \n",
       "1600        keeps          kee            kpeep  \n",
       "\n",
       "[1601 rows x 8 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed_correction_df = get_correction_df(DATA_PATH + \"\\ed_correction_df.csv\", typos, editdistance.eval, True, 5)\n",
    "\n",
    "ed_typo_df = pd.concat([typo_df, ed_correction_df], axis=1)\n",
    "ed_typo_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Return the text file with the corrections \n",
    "\n",
    "### 1.4.1 Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_correction(typo_row):\n",
    "    name = typo_row[\"Word\"]\n",
    "    typo = typo_row['Typo']\n",
    "    neigh0 = typo_row[0]\n",
    "    neigh1 = typo_row[1]\n",
    "    neigh2 = typo_row[2]\n",
    "    neigh3 = typo_row[3]\n",
    "    neigh4 = typo_row[4]\n",
    "    return f\"<correction orig=\\\"{name}\\\" typo=\\\"{typo}\\\">{neigh0} {neigh1} {neigh2} {neigh3} {neigh4}</correction>\"\n",
    "\n",
    "def format_typo(typo_row):\n",
    "    orig = typo_row[\"Word\"]\n",
    "    typo = typo_row['Typo']\n",
    "    return f'<typo orig=\"{orig}\">{typo}</typo>'\n",
    "\n",
    "def replace_typos(path, typo_df, typos_str): \n",
    " \n",
    "    formatted_corr = typo_df.apply(format_correction, axis=1)\n",
    "    formatted_typo = typo_df.apply(format_typo, axis=1)\n",
    "\n",
    "    formatted_dict = dict(zip(formatted_typo, formatted_corr))\n",
    "\n",
    "    # Erase the contents of the file if it already exists\n",
    "    if os.path.isfile(path):\n",
    "        os.remove(path)\n",
    "\n",
    "    for typo_pattern in formatted_dict.keys():\n",
    "        correction_pattern = formatted_dict[typo_pattern]\n",
    "        typos_str = re.sub(typo_pattern, correction_pattern, typos_str)\n",
    "\n",
    "    # Write it to a .txt file\n",
    "    with open(path, \"a\") as out_file:\n",
    "        out_file.write(typos_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.2 Replace typos for all distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "typos_file = open(DATA_PATH + r\"\\typo-0.2.txt\").read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jaro**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_typos(DATA_PATH + \"\\jaro_corrections-0.2.txt\", jaro_typo_df, typos_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jaro-Winkler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_typos(DATA_PATH + \"\\jw_corrections-0.2.txt\", jw_typo_df, typos_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Edit Distance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_typos(DATA_PATH + \"\\ed_corrections-0.2.txt\", ed_typo_df, typos_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
