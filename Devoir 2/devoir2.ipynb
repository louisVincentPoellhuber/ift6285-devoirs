{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Initialisation\n",
    "\n",
    "## 0.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import chardet\n",
    "import editdistance\n",
    "import jellyfish\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATA_PATH = r\"C:\\Users\\Louis\\Documents\\University\\Masters\\A23\\NLP\\Devoirs\\data\\hw2\"\n",
    "#DATA_PATH = r\"C:\\Users\\barka\\Desktop\\NLP\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_encoding(file_path):\n",
    "\n",
    "    with open(file_path, 'rb') as file:\n",
    "        rawdata = file.read()\n",
    "    result = chardet.detect(rawdata)\n",
    "    return result['encoding']\n",
    "\n",
    "def get_word_counter(file_path, encoding):\n",
    "    word_counter = Counter()\n",
    "\n",
    "    with open(file_path, 'r', encoding=encoding) as file:\n",
    "        for line in file:\n",
    "            \n",
    "            parts = line.split()\n",
    "            if len(parts) >= 2:\n",
    "                word = parts[1]\n",
    "                \n",
    "                word_counter[word.strip()] += 1\n",
    "\n",
    "    # Return the Counter containing word frequencies\n",
    "    return word_counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.3 Check data quality\n",
    "Make sure Python is reading the lines correctly. And it does!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1000 rows in the file. There should be 1000. Correct number? True\n",
      "Encoding : utf-8\n",
      "There are 201315 rows in the file. There should be 201 315. Correct number? True\n"
     ]
    }
   ],
   "source": [
    "# Check ypos\n",
    "typos_file = open(DATA_PATH + r\"\\typo-0.2.txt\")\n",
    "\n",
    "for i, row in enumerate(typos_file):\n",
    "    #print(row)\n",
    "    pass\n",
    "\n",
    "print(f\"There are {i+1} rows in the file. There should be 1000. Correct number? {i+1==1000}\")\n",
    "\n",
    "# Check vocabulary\n",
    "\n",
    "encoding = detect_encoding(DATA_PATH + r\"\\voc-1bwc.txt\") #check encoding\n",
    "print(f\"Encoding : {encoding}\")\n",
    "\n",
    "voc = open(DATA_PATH + r\"\\voc-1bwc.txt\", encoding=encoding)\n",
    "\n",
    "for i, row in enumerate(voc):\n",
    "    #print(row)\n",
    "    pass\n",
    "\n",
    "print(f\"There are {i+1} rows in the file. There should be 201 315. Correct number? {i+1==201315}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many words in the vocabulary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201315\n"
     ]
    }
   ],
   "source": [
    "vocab = get_word_counter(DATA_PATH + r\"\\voc-1bwc.txt\", encoding)\n",
    "print(len(vocab)) # just to verify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Implementing various distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Distance functions\n",
    "\n",
    "### 1.1.a - Edit distance \n",
    "Taken from the blog, edited to return any number of likely words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P(word, N=sum(vocab.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return vocab[word] / N\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    huh = candidates(word)\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in vocab)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.b -  Jaro distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaro_correction(word):\n",
    "    \n",
    "    max_distance = float('-inf')\n",
    "    max_word = \"\"\n",
    "    \n",
    "    for w in vocab :\n",
    "        \n",
    "        distance = jellyfish.jaro_similarity(word, w)\n",
    "        \n",
    "        if max_distance < distance :\n",
    "            \n",
    "            max_distance = distance\n",
    "            max_word = w\n",
    "    \n",
    "    return max_word, max_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.c -  Jaro-Winkler distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaro_winkler_correction(word):\n",
    "    max_distance = float('-inf')\n",
    "    max_word = \"\"\n",
    "    \n",
    "    for w in vocab :\n",
    "        \n",
    "        distance = jellyfish.jaro_winkler_similarity(word, w)\n",
    "        \n",
    "        if max_distance < distance :\n",
    "            \n",
    "            max_distance = distance\n",
    "            max_word = w\n",
    "    \n",
    "    return max_word, max_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.d Generic Distance function\n",
    "\n",
    "Works with any function that takes two words as an input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This function applies a generic function over an entire vocabulary to compare the distance between a given word\n",
    "and every word inside the vocabulary. It then returns the n_neighbors most similar words.\n",
    "\n",
    "Parameters:\n",
    "    word: The word to find neighbors to.\n",
    "    vocabulary: A list (or list-like) of the vocabulary.\n",
    "    func: The distance function to apply without arguments (without parentheses).\n",
    "    minimum: Do we want the minimum distance? Boolean. True by default, will yield the minimum distance. If False, the function will yield the maximum distance. \n",
    "    n_neighbors: The number of most similar words to return.\n",
    "\n",
    "Returns:\n",
    "    vocabulary.head: A dataframe containing the n_neighbors most similar words to the input word, with the distances. \n",
    "'''\n",
    "def generic_distance_correction(word, vocabulary, func, minimum = True, n_neighbors=1):\n",
    "    vocabulary = pd.DataFrame(vocabulary, columns=[\"words\"])\n",
    "\n",
    "    def calculateDistance(series_word):\n",
    "        return func(series_word, word)\n",
    "    \n",
    "    distances = vocabulary[\"words\"].apply(calculateDistance)\n",
    "    \n",
    "    vocabulary[\"distance\"] = distances\n",
    "\n",
    "    if minimum:\n",
    "        vocabulary = vocabulary.sort_values(\"distance\", ascending=True)\n",
    "    else: \n",
    "        vocabulary = vocabulary.sort_values(\"distance\", ascending=False)\n",
    "\n",
    "    return vocabulary.head(n_neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Testing the correction methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>177635</th>\n",
       "      <td>spewing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189762</th>\n",
       "      <td>spelling</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171215</th>\n",
       "      <td>sperling</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174478</th>\n",
       "      <td>smelling</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185401</th>\n",
       "      <td>spilling</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           words  distance\n",
       "177635   spewing         1\n",
       "189762  spelling         1\n",
       "171215  sperling         1\n",
       "174478  smelling         2\n",
       "185401  spilling         2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generic_distance_correction('speling', vocab.keys(), editdistance.eval, True, 5) #Edit distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>171215</th>\n",
       "      <td>sperling</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189762</th>\n",
       "      <td>spelling</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167278</th>\n",
       "      <td>spellings</td>\n",
       "      <td>0.925926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196330</th>\n",
       "      <td>sleeping</td>\n",
       "      <td>0.910714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126688</th>\n",
       "      <td>sapling</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            words  distance\n",
       "171215   sperling  0.958333\n",
       "189762   spelling  0.958333\n",
       "167278  spellings  0.925926\n",
       "196330   sleeping  0.910714\n",
       "126688    sapling  0.904762"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generic_distance_correction('speling', vocab.keys(), jellyfish.jaro_similarity, False, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>189762</th>\n",
       "      <td>spelling</td>\n",
       "      <td>0.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171215</th>\n",
       "      <td>sperling</td>\n",
       "      <td>0.970833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167278</th>\n",
       "      <td>spellings</td>\n",
       "      <td>0.955556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177635</th>\n",
       "      <td>spewing</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196330</th>\n",
       "      <td>sleeping</td>\n",
       "      <td>0.919643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            words  distance\n",
       "189762   spelling  0.975000\n",
       "171215   sperling  0.970833\n",
       "167278  spellings  0.955556\n",
       "177635    spewing  0.933333\n",
       "196330   sleeping  0.919643"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generic_distance_correction('speling', vocab.keys(), jellyfish.jaro_winkler_similarity, False, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sperling', 0.9583333333333334)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaro_correction('speling') #Jaro distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('spelling', 0.975)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaro_winkler_correction('speling') #Jaro-Winkler distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Running the correction methods on the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 - Get the typos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_PATH + r\"\\typo-0.2.txt\", \"r\", encoding=encoding) as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Regex\n",
    "typo_pattern = r'<typo orig=\"([^\"]+)\">([^<]+)</typo>'\n",
    "typos = re.findall(typo_pattern, text)\n",
    "typos = dict(typos)\n",
    "typo_df = pd.DataFrame(index = typos.keys())\n",
    "typo_df[\"Typo\"] = typos.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 - Apply correction methods: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Correcting Typos: 100%|██████████| 1601/1601 [03:58<00:00,  6.72it/s]\n"
     ]
    }
   ],
   "source": [
    "corrected_typos = dict()\n",
    "\n",
    "for orig, typo in tqdm(typos.items(), desc=\"Correcting Typos\"):\n",
    "    correction = jaro_winkler_correction(typo)[0]  # Jaro-Winkler distance\n",
    "    corrected_typos[orig] = correction\n",
    "\n",
    "print(f\" Number of corrected typos : {len(corrected_typos)}\")\n",
    "print(f\" Number of typos : {len(typos)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Correcting Typos: 100%|██████████| 1601/1601 [04:50<00:00,  5.52it/s]\n"
     ]
    }
   ],
   "source": [
    "correction_df = pd.DataFrame()\n",
    "\n",
    "for orig, typo in tqdm(typos.items(), desc=\"Correcting Typos\"):\n",
    "    corrections = generic_distance_correction(typo, vocab.keys(), jellyfish.jaro_winkler_similarity, False, 5)  # Jaro-Winkler distance\n",
    "    row = corrections[\"words\"].reset_index(drop=True)\n",
    "    row.name = orig\n",
    "    correction_df = pd.concat([correction_df, row], axis=1)\n",
    "correction_df = correction_df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Typo</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wealthy</th>\n",
       "      <td>wealtohy</td>\n",
       "      <td>wealthy</td>\n",
       "      <td>wealth</td>\n",
       "      <td>weal</td>\n",
       "      <td>wealthtv</td>\n",
       "      <td>welty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>afford</th>\n",
       "      <td>aford</td>\n",
       "      <td>afford</td>\n",
       "      <td>axford</td>\n",
       "      <td>alford</td>\n",
       "      <td>ford</td>\n",
       "      <td>affords</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Catholic</th>\n",
       "      <td>CatholiaCtholic</td>\n",
       "      <td>athol</td>\n",
       "      <td>palaeolithic</td>\n",
       "      <td>pathological</td>\n",
       "      <td>alghaithi</td>\n",
       "      <td>toit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cousins</th>\n",
       "      <td>coxusins</td>\n",
       "      <td>cousins</td>\n",
       "      <td>cousin</td>\n",
       "      <td>coxswain</td>\n",
       "      <td>compulsions</td>\n",
       "      <td>coun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>masks</th>\n",
       "      <td>mmasks</td>\n",
       "      <td>masks</td>\n",
       "      <td>mask</td>\n",
       "      <td>mass</td>\n",
       "      <td>asks</td>\n",
       "      <td>mma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plummeted</th>\n",
       "      <td>plummete</td>\n",
       "      <td>plummeted</td>\n",
       "      <td>plummet</td>\n",
       "      <td>plummetted</td>\n",
       "      <td>plummets</td>\n",
       "      <td>plume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>posts</th>\n",
       "      <td>psts</td>\n",
       "      <td>pst</td>\n",
       "      <td>pests</td>\n",
       "      <td>pasts</td>\n",
       "      <td>posts</td>\n",
       "      <td>psst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>defy</th>\n",
       "      <td>deefy</td>\n",
       "      <td>defy</td>\n",
       "      <td>deep-fry</td>\n",
       "      <td>deery</td>\n",
       "      <td>dee</td>\n",
       "      <td>deeny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>translation</th>\n",
       "      <td>translatmion</td>\n",
       "      <td>translation</td>\n",
       "      <td>translations</td>\n",
       "      <td>translational</td>\n",
       "      <td>translating</td>\n",
       "      <td>transaction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keep</th>\n",
       "      <td>kpeep</td>\n",
       "      <td>keep</td>\n",
       "      <td>peep</td>\n",
       "      <td>kpe</td>\n",
       "      <td>keeps</td>\n",
       "      <td>kee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1601 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Typo            0             1              2  \\\n",
       "wealthy             wealtohy      wealthy        wealth           weal   \n",
       "afford                 aford       afford        axford         alford   \n",
       "Catholic     CatholiaCtholic        athol  palaeolithic   pathological   \n",
       "cousins             coxusins      cousins        cousin       coxswain   \n",
       "masks                 mmasks        masks          mask           mass   \n",
       "...                      ...          ...           ...            ...   \n",
       "plummeted           plummete    plummeted       plummet     plummetted   \n",
       "posts                   psts          pst         pests          pasts   \n",
       "defy                   deefy         defy      deep-fry          deery   \n",
       "translation     translatmion  translation  translations  translational   \n",
       "keep                   kpeep         keep          peep            kpe   \n",
       "\n",
       "                       3            4  \n",
       "wealthy         wealthtv        welty  \n",
       "afford              ford      affords  \n",
       "Catholic       alghaithi         toit  \n",
       "cousins      compulsions         coun  \n",
       "masks               asks          mma  \n",
       "...                  ...          ...  \n",
       "plummeted       plummets        plume  \n",
       "posts              posts         psst  \n",
       "defy                 dee        deeny  \n",
       "translation  translating  transaction  \n",
       "keep               keeps          kee  \n",
       "\n",
       "[1601 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typo_df = pd.concat([typo_df, correction_df], axis=1)\n",
    "typo_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return the text file with the corrections : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_output(typo_row):\n",
    "    return f\"<correction orig=\\\"{typo_row.name}\\\" typo=\\\"{typo_row['Typo']}\\\">{typo_row[0]} {typo_row[1]} {typo_row[2]} {typo_row[3]} {typo_row[4]}</correction>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "format_output() got an unexpected keyword argument 'by_row'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Louis\\Documents\\University\\Masters\\A23\\NLP\\Devoirs\\ift6285-devoirs\\Devoir 2\\devoir2.ipynb Cell 33\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Louis/Documents/University/Masters/A23/NLP/Devoirs/ift6285-devoirs/Devoir%202/devoir2.ipynb#X50sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m typo_df\u001b[39m.\u001b[39;49mapply(format_output, by_row\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\frame.py:9568\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   9557\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[0;32m   9559\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[0;32m   9560\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   9561\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9566\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[0;32m   9567\u001b[0m )\n\u001b[1;32m-> 9568\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\apply.py:764\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[0;32m    762\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[1;32m--> 764\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\apply.py:891\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 891\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[0;32m    893\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[0;32m    894\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\apply.py:907\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    904\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    905\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[0;32m    906\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 907\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[0;32m    908\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    909\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    910\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    911\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\apply.py:142\u001b[0m, in \u001b[0;36mApply.__init__.<locals>.f\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf\u001b[39m(x):\n\u001b[1;32m--> 142\u001b[0m     \u001b[39mreturn\u001b[39;00m func(x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: format_output() got an unexpected keyword argument 'by_row'"
     ]
    }
   ],
   "source": [
    "typo_df.apply(format_output, by_row=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
