{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Initialisation\n",
    "\n",
    "## 0.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import chardet\n",
    "import editdistance #\n",
    "import jellyfish\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "#DATA_PATH = r\"C:\\Users\\Louis\\Documents\\University\\Masters\\A23\\NLP\\Devoirs\\data\\hw2\"\n",
    "DATA_PATH = r\"C:\\Users\\barka\\Desktop\\NLP\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_encoding(file_path):\n",
    "\n",
    "    with open(file_path, 'rb') as file:\n",
    "        rawdata = file.read()\n",
    "    result = chardet.detect(rawdata)\n",
    "    return result['encoding']\n",
    "\n",
    "def get_word_counter(file_path, encoding):\n",
    "    word_counter = Counter()\n",
    "\n",
    "    with open(file_path, 'r', encoding=encoding) as file:\n",
    "        for line in file:\n",
    "            \n",
    "            parts = line.split()\n",
    "            if len(parts) >= 2:\n",
    "                word = parts[1]\n",
    "                \n",
    "                word_counter[word.strip()] += 1\n",
    "\n",
    "    # Return the Counter containing word frequencies\n",
    "    return word_counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.3 Check data quality\n",
    "Make sure Python is reading the lines correctly. And it does!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1000 rows in the file. There should be 1000. Correct number? True\n",
      "Encoding : utf-8\n",
      "There are 201315 rows in the file. There should be 201 315. Correct number? True\n"
     ]
    }
   ],
   "source": [
    "# Check ypos\n",
    "typos_file = open(DATA_PATH + r\"\\typo-0.2.txt\")\n",
    "\n",
    "for i, row in enumerate(typos_file):\n",
    "    #print(row)\n",
    "    pass\n",
    "\n",
    "print(f\"There are {i+1} rows in the file. There should be 1000. Correct number? {i+1==1000}\")\n",
    "\n",
    "# Check vocabulary\n",
    "\n",
    "encoding = detect_encoding(DATA_PATH + r\"\\voc-1bwc.txt\") #check encoding\n",
    "print(f\"Encoding : {encoding}\")\n",
    "\n",
    "voc = open(DATA_PATH + r\"\\voc-1bwc.txt\", encoding=encoding)\n",
    "\n",
    "for i, row in enumerate(voc):\n",
    "    #print(row)\n",
    "    pass\n",
    "\n",
    "print(f\"There are {i+1} rows in the file. There should be 201 315. Correct number? {i+1==201315}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many words in the vocabulary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201315\n"
     ]
    }
   ],
   "source": [
    "vocab = get_word_counter(DATA_PATH + r\"\\voc-1bwc.txt\", encoding)\n",
    "print(len(vocab)) # just to verify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Implementing various distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Generic Distance function\n",
    "\n",
    "Works with any function that takes two words as an input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This function applies a generic function over an entire vocabulary to compare the distance between a given word\n",
    "and every word inside the vocabulary. It then returns the n_neighbors most similar words.\n",
    "\n",
    "Parameters:\n",
    "    word: The word to find neighbors to.\n",
    "    vocabulary: A list (or list-like) of the vocabulary.\n",
    "    func: The distance function to apply without arguments (without parentheses).\n",
    "    minimum: Do we want the minimum distance? Boolean. True by default, will yield the minimum distance. If False, the function will yield the maximum distance. \n",
    "    n_neighbors: The number of most similar words to return.\n",
    "\n",
    "Returns:\n",
    "    vocabulary.head: A dataframe containing the n_neighbors most similar words to the input word, with the distances. \n",
    "'''\n",
    "def generic_distance_correction(word, vocabulary, func, minimum = True, n_neighbors=1):\n",
    "    vocabulary = pd.DataFrame(vocabulary, columns=[\"words\"])\n",
    "\n",
    "    def calculateDistance(series_word):\n",
    "        return func(series_word, word)\n",
    "    \n",
    "    distances = vocabulary[\"words\"].apply(calculateDistance)\n",
    "    \n",
    "    vocabulary[\"distance\"] = distances\n",
    "\n",
    "    if minimum:\n",
    "        vocabulary = vocabulary.sort_values(\"distance\", ascending=True)\n",
    "    else: \n",
    "        vocabulary = vocabulary.sort_values(\"distance\", ascending=False)\n",
    "\n",
    "    return vocabulary.head(n_neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Testing the correction methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>171215</th>\n",
       "      <td>sperling</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177635</th>\n",
       "      <td>spewing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189762</th>\n",
       "      <td>spelling</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131284</th>\n",
       "      <td>pelling</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180918</th>\n",
       "      <td>sewing</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           words  distance\n",
       "171215  sperling         1\n",
       "177635   spewing         1\n",
       "189762  spelling         1\n",
       "131284   pelling         2\n",
       "180918    sewing         2"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generic_distance_correction('speling', vocab.keys(), editdistance.eval, True, 5) #Edit distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>189762</th>\n",
       "      <td>spelling</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171215</th>\n",
       "      <td>sperling</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167278</th>\n",
       "      <td>spellings</td>\n",
       "      <td>0.925926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196330</th>\n",
       "      <td>sleeping</td>\n",
       "      <td>0.910714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200045</th>\n",
       "      <td>selling</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            words  distance\n",
       "189762   spelling  0.958333\n",
       "171215   sperling  0.958333\n",
       "167278  spellings  0.925926\n",
       "196330   sleeping  0.910714\n",
       "200045    selling  0.904762"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generic_distance_correction('speling', vocab.keys(), jellyfish.jaro_similarity, False, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>189762</th>\n",
       "      <td>spelling</td>\n",
       "      <td>0.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171215</th>\n",
       "      <td>sperling</td>\n",
       "      <td>0.970833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167278</th>\n",
       "      <td>spellings</td>\n",
       "      <td>0.955556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177635</th>\n",
       "      <td>spewing</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196330</th>\n",
       "      <td>sleeping</td>\n",
       "      <td>0.919643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            words  distance\n",
       "189762   spelling  0.975000\n",
       "171215   sperling  0.970833\n",
       "167278  spellings  0.955556\n",
       "177635    spewing  0.933333\n",
       "196330   sleeping  0.919643"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generic_distance_correction('speling', vocab.keys(), jellyfish.jaro_winkler_similarity, False, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Running the correction methods on the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 - Get the typos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Typo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3173</th>\n",
       "      <td>defy</td>\n",
       "      <td>deefy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3174</th>\n",
       "      <td>translation</td>\n",
       "      <td>translatmion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3175</th>\n",
       "      <td>to</td>\n",
       "      <td>tho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3176</th>\n",
       "      <td>But</td>\n",
       "      <td>ut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3177</th>\n",
       "      <td>in</td>\n",
       "      <td>ini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3178</th>\n",
       "      <td>keep</td>\n",
       "      <td>kpeep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3179</th>\n",
       "      <td>game</td>\n",
       "      <td>gme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3180</th>\n",
       "      <td>winds</td>\n",
       "      <td>wantagh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3181</th>\n",
       "      <td>this</td>\n",
       "      <td>tsi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3182</th>\n",
       "      <td>of</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Word          Typo\n",
       "3173         defy         deefy\n",
       "3174  translation  translatmion\n",
       "3175           to           tho\n",
       "3176          But            ut\n",
       "3177           in           ini\n",
       "3178         keep         kpeep\n",
       "3179         game           gme\n",
       "3180        winds       wantagh\n",
       "3181         this           tsi\n",
       "3182           of             o"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(DATA_PATH + r\"\\typo-0.2.txt\", \"r\", encoding=encoding) as file:\n",
    "    text = file.read()\n",
    "\n",
    "\n",
    "typo_pattern = r'<typo orig=\"([^\"]+)\">([^<]+)</typo>'\n",
    "\n",
    "\n",
    "typos = re.findall(typo_pattern, text)\n",
    "\n",
    "\n",
    "typos = pd.DataFrame(typos, columns=[\"Word\", \"Typo\"])\n",
    "\n",
    "\n",
    "typos.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 - Apply correction methods: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correction_df(path, typos, func, minimum = True, n_neighbors=1):\n",
    "\n",
    "    if os.path.isfile(path):\n",
    "        final_df = pd.read_csv(path, index_col = 0)\n",
    "\n",
    "    else: \n",
    "        \n",
    "        final_df = typos.copy()\n",
    "        rows = pd.DataFrame() \n",
    "\n",
    "\n",
    "        for i, typo in tqdm(enumerate(typos[\"Typo\"].tolist()), desc=\"Correcting Typos\", total=len(typos)):\n",
    "            \n",
    "            \n",
    "            \n",
    "            corrections = generic_distance_correction(typo, vocab.keys(), func, minimum, n_neighbors)\n",
    "            new_row = corrections.transpose().reset_index(drop=True)\n",
    "            \n",
    "            new_row.columns = [str(i) for i in range(len(new_row.columns))]\n",
    "            \n",
    "            new_row = pd.concat([new_row.iloc[0], new_row.iloc[1]], axis=0)\n",
    "            new_row = new_row.reset_index(drop=True)\n",
    "            \n",
    "            new_row = pd.DataFrame(new_row)\n",
    "            \n",
    "            row = pd.DataFrame()\n",
    "            \n",
    "            print(new_row)\n",
    "            \n",
    "            for col in new_row.columns:\n",
    "                \n",
    "                if int(col) > 4 : row[f\"d{col-n_neighbors}\"] = new_row[col]\n",
    "                    \n",
    "                else: row[col] = new_row[col]\n",
    "            \n",
    "            \n",
    "            if i == 10 : break\n",
    "                \n",
    "            rows = pd.concat([rows, row], axis=1)\n",
    "            \n",
    "        \n",
    "        print(rows)\n",
    "        \n",
    "        final_df = pd.concat([final_df, rows], axis=0)\n",
    "            \n",
    "        print(final_df)\n",
    "        \n",
    "\n",
    "        final_df.to_csv(path)\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Jaro**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Correcting Typos:   0%|                                                               | 1/3183 [00:00<14:14,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0\n",
      "0   wealthy\n",
      "1    wealth\n",
      "2     welty\n",
      "3   healthy\n",
      "4    watley\n",
      "5  0.958333\n",
      "6  0.916667\n",
      "7     0.875\n",
      "8  0.869048\n",
      "9  0.861111\n",
      "          0\n",
      "0    axford\n",
      "1    afford\n",
      "2    alford\n",
      "3      ford\n",
      "4   walford\n",
      "5  0.944444\n",
      "6  0.944444\n",
      "7  0.944444\n",
      "8  0.933333\n",
      "9  0.904762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Correcting Typos:   0%|                                                               | 3/3183 [00:00<12:05,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0\n",
      "0         athol\n",
      "1  pathological\n",
      "2  palaeolithic\n",
      "3     alghaithi\n",
      "4          holi\n",
      "5      0.777778\n",
      "6      0.766667\n",
      "7      0.766667\n",
      "8      0.765741\n",
      "9      0.755556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Correcting Typos:   0%|                                                               | 5/3183 [00:01<11:46,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0\n",
      "0      cousins\n",
      "1       cousin\n",
      "2  compulsions\n",
      "3     coxswain\n",
      "4     cushions\n",
      "5     0.958333\n",
      "6     0.916667\n",
      "7     0.837121\n",
      "8     0.833333\n",
      "9     0.833333\n",
      "          0\n",
      "0     masks\n",
      "1      asks\n",
      "2      mass\n",
      "3      mask\n",
      "4   unmasks\n",
      "5  0.944444\n",
      "6  0.888889\n",
      "7  0.888889\n",
      "8  0.888889\n",
      "9  0.849206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Correcting Typos:   0%|▏                                                              | 7/3183 [00:01<11:03,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0\n",
      "0       tos\n",
      "1      tons\n",
      "2      toms\n",
      "3      toss\n",
      "4      taos\n",
      "5       1.0\n",
      "6  0.916667\n",
      "7  0.916667\n",
      "8  0.916667\n",
      "9  0.916667\n",
      "          0\n",
      "0       bac\n",
      "1       bsa\n",
      "2       bro\n",
      "3       bks\n",
      "4       ble\n",
      "5  0.777778\n",
      "6  0.777778\n",
      "7  0.777778\n",
      "8  0.777778\n",
      "9  0.777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Correcting Typos:   0%|▏                                                              | 8/3183 [00:01<11:23,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0\n",
      "0   rockers\n",
      "1   brokers\n",
      "2     roker\n",
      "3   workers\n",
      "4   yorkers\n",
      "5  0.952381\n",
      "6  0.952381\n",
      "7  0.944444\n",
      "8  0.896825\n",
      "9  0.896825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Correcting Typos:   0%|▏                                                              | 9/3183 [00:02<12:20,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0\n",
      "0      tthe\n",
      "1     tithe\n",
      "2     tothe\n",
      "3       the\n",
      "4    tithes\n",
      "5       1.0\n",
      "6  0.933333\n",
      "7  0.933333\n",
      "8  0.916667\n",
      "9  0.888889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Correcting Typos:   0%|▏                                                             | 10/3183 [00:02<13:27,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0\n",
      "0   government\n",
      "1  government-\n",
      "2  governments\n",
      "3    governent\n",
      "4   governemnt\n",
      "5          1.0\n",
      "6     0.969697\n",
      "7     0.969697\n",
      "8     0.966667\n",
      "9     0.966667\n",
      "          0\n",
      "0      fist\n",
      "1     feist\n",
      "2     fists\n",
      "3     foist\n",
      "4     first\n",
      "5       1.0\n",
      "6  0.933333\n",
      "7  0.933333\n",
      "8  0.933333\n",
      "9  0.933333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "InvalidIndexError",
     "evalue": "Reindexing only valid with uniquely valued Index objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14228\\1027648514.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mjaro_correction_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_correction_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\jaro_correction_df.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtypos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjellyfish\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjaro_similarity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mjaro_correction_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14228\\3724839723.py\u001b[0m in \u001b[0;36mget_correction_df\u001b[1;34m(path, typos, func, minimum, n_neighbors)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mfinal_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfinal_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    358\u001b[0m     )\n\u001b[0;32m    359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    589\u001b[0m                     \u001b[0mobj_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m                         \u001b[0mindexers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   3727\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3728\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index_as_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3729\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_requires_unique_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3730\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3731\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: Reindexing only valid with uniquely valued Index objects"
     ]
    }
   ],
   "source": [
    "jaro_correction_df = get_correction_df(DATA_PATH + \"\\jaro_correction_df.csv\", typos, jellyfish.jaro_similarity, False, 5)\n",
    "jaro_correction_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jaro-Winkler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Correcting Typos: 100%|████████████████████████████████████████████████████████████| 3183/3183 [12:28<00:00,  4.25it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Typo</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wealthy</td>\n",
       "      <td>wealtohy</td>\n",
       "      <td>wealthy</td>\n",
       "      <td>wealth</td>\n",
       "      <td>welty</td>\n",
       "      <td>weal</td>\n",
       "      <td>wealthtv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>afford</td>\n",
       "      <td>aford</td>\n",
       "      <td>afford</td>\n",
       "      <td>alford</td>\n",
       "      <td>axford</td>\n",
       "      <td>ford</td>\n",
       "      <td>affords</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Catholic</td>\n",
       "      <td>CatholiaCtholic</td>\n",
       "      <td>athol</td>\n",
       "      <td>pathological</td>\n",
       "      <td>palaeolithic</td>\n",
       "      <td>alghaithi</td>\n",
       "      <td>holi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cousins</td>\n",
       "      <td>coxusins</td>\n",
       "      <td>cousins</td>\n",
       "      <td>cousin</td>\n",
       "      <td>coxswain</td>\n",
       "      <td>compulsions</td>\n",
       "      <td>cosiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>masks</td>\n",
       "      <td>mmasks</td>\n",
       "      <td>masks</td>\n",
       "      <td>mask</td>\n",
       "      <td>mass</td>\n",
       "      <td>asks</td>\n",
       "      <td>mma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3178</th>\n",
       "      <td>keep</td>\n",
       "      <td>kpeep</td>\n",
       "      <td>keep</td>\n",
       "      <td>peep</td>\n",
       "      <td>kpe</td>\n",
       "      <td>kee</td>\n",
       "      <td>keeps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3179</th>\n",
       "      <td>game</td>\n",
       "      <td>gme</td>\n",
       "      <td>gme</td>\n",
       "      <td>gmes</td>\n",
       "      <td>game</td>\n",
       "      <td>gome</td>\n",
       "      <td>gomez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3180</th>\n",
       "      <td>winds</td>\n",
       "      <td>wantagh</td>\n",
       "      <td>wantagh</td>\n",
       "      <td>wantage</td>\n",
       "      <td>want</td>\n",
       "      <td>wana</td>\n",
       "      <td>wang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3181</th>\n",
       "      <td>this</td>\n",
       "      <td>tsi</td>\n",
       "      <td>tsi</td>\n",
       "      <td>tsim</td>\n",
       "      <td>tsoi</td>\n",
       "      <td>tsai</td>\n",
       "      <td>tsui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3182</th>\n",
       "      <td>of</td>\n",
       "      <td>o</td>\n",
       "      <td>osk</td>\n",
       "      <td>okd</td>\n",
       "      <td>ote</td>\n",
       "      <td>oia</td>\n",
       "      <td>oro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3183 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word             Typo        0             1             2  \\\n",
       "0      wealthy         wealtohy  wealthy        wealth         welty   \n",
       "1       afford            aford   afford        alford        axford   \n",
       "2     Catholic  CatholiaCtholic    athol  pathological  palaeolithic   \n",
       "3      cousins         coxusins  cousins        cousin      coxswain   \n",
       "4        masks           mmasks    masks          mask          mass   \n",
       "...        ...              ...      ...           ...           ...   \n",
       "3178      keep            kpeep     keep          peep           kpe   \n",
       "3179      game              gme      gme          gmes          game   \n",
       "3180     winds          wantagh  wantagh       wantage          want   \n",
       "3181      this              tsi      tsi          tsim          tsoi   \n",
       "3182        of                o      osk           okd           ote   \n",
       "\n",
       "                3         4  \n",
       "0            weal  wealthtv  \n",
       "1            ford   affords  \n",
       "2       alghaithi      holi  \n",
       "3     compulsions  cosiness  \n",
       "4            asks       mma  \n",
       "...           ...       ...  \n",
       "3178          kee     keeps  \n",
       "3179         gome     gomez  \n",
       "3180         wana      wang  \n",
       "3181         tsai      tsui  \n",
       "3182          oia       oro  \n",
       "\n",
       "[3183 rows x 7 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jw_correction_df = get_correction_df(DATA_PATH + \"\\jw_correction_df.csv\", typos, jellyfish.jaro_winkler_similarity, False, 5)\n",
    "jw_correction_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Edit Distance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Correcting Typos:  22%|█████████████▏                                               | 691/3183 [06:24<23:06,  1.80it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14228\\668306705.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0med_correction_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_correction_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\ed_correction_df.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtypos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meditdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0med_correction_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14228\\2321311557.py\u001b[0m in \u001b[0;36mget_correction_df\u001b[1;34m(path, typos, func, minimum, n_neighbors)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0mcorrections\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgeneric_distance_correction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtypo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminimum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorrections\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"words\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14228\\1912312824.py\u001b[0m in \u001b[0;36mgeneric_distance_correction\u001b[1;34m(word, vocabulary, func, minimum, n_neighbors)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_word\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mdistances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"words\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcalculateDistance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"distance\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdistances\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4431\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4432\u001b[0m         \"\"\"\n\u001b[1;32m-> 4433\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4435\u001b[0m     def _reduce(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1086\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1087\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1088\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1089\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1141\u001b[0m                 \u001b[1;31m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m                 \u001b[1;31m# \"Callable[[Any], Any]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1143\u001b[1;33m                 mapped = lib.map_infer(\n\u001b[0m\u001b[0;32m   1144\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m                     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14228\\1912312824.py\u001b[0m in \u001b[0;36mcalculateDistance\u001b[1;34m(series_word)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mvocabulary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"words\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mcalculateDistance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_word\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ed_correction_df = get_correction_df(DATA_PATH + \"\\ed_correction_df.csv\", typos, editdistance.eval, True, 5)\n",
    "ed_correction_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Return the text file with the corrections \n",
    "\n",
    "### 1.4.1 Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_correction(typo_row):\n",
    "    name = typo_row[\"Word\"]\n",
    "    typo = typo_row['Typo']\n",
    "    neigh0 = typo_row[0]\n",
    "    neigh1 = typo_row[1]\n",
    "    neigh2 = typo_row[2]\n",
    "    neigh3 = typo_row[3]\n",
    "    neigh4 = typo_row[4]\n",
    "    return f\"<correction orig=\\\"{name}\\\" typo=\\\"{typo}\\\">{neigh0} {neigh1} {neigh2} {neigh3} {neigh4}</correction>\"\n",
    "\n",
    "def format_typo(typo_row):\n",
    "    orig = typo_row[\"Word\"]\n",
    "    typo = typo_row['Typo']\n",
    "    return f'<typo orig=\"{orig}\">{typo}</typo>'\n",
    "\n",
    "def replace_typos(path, typo_df, typos_str): \n",
    " \n",
    "    formatted_corr = typo_df.apply(format_correction, axis=1)\n",
    "    formatted_typo = typo_df.apply(format_typo, axis=1)\n",
    "\n",
    "    formatted_dict = dict(zip(formatted_typo, formatted_corr))\n",
    "\n",
    "    # Erase the contents of the file if it already exists\n",
    "    if os.path.isfile(path):\n",
    "        os.remove(path)\n",
    "\n",
    "    for typo_pattern in formatted_dict.keys():\n",
    "        correction_pattern = formatted_dict[typo_pattern]\n",
    "        typos_str = re.sub(typo_pattern, correction_pattern, typos_str)\n",
    "\n",
    "    # Write it to a .txt file\n",
    "    with open(path, \"a\") as out_file:\n",
    "        out_file.write(typos_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.2 Replace typos for all distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typos_file = open(DATA_PATH + r\"\\typo-0.2.txt\").read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jaro**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_typos(DATA_PATH + \"\\jaro_corrections-0.2.txt\", jaro_typo_df, typos_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jaro-Winkler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_typos(DATA_PATH + \"\\jw_corrections-0.2.txt\", jw_typo_df, typos_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Edit Distance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_typos(DATA_PATH + \"\\ed_corrections-0.2.txt\", ed_typo_df, typos_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
