{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Initialisation\n",
    "\n",
    "## 0.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\barka\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import chardet\n",
    "import editdistance #\n",
    "import jellyfish\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import Levenshtein\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#DATA_PATH = r\"C:\\Users\\Louis\\Documents\\University\\Masters\\A23\\NLP\\Devoirs\\data\\hw2\"\n",
    "DATA_PATH = r\"C:\\Users\\barka\\Desktop\\NLP\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_encoding(file_path):\n",
    "\n",
    "    with open(file_path, 'rb') as file:\n",
    "        rawdata = file.read()\n",
    "    result = chardet.detect(rawdata)\n",
    "    return result['encoding']\n",
    "\n",
    "def get_word_counter(file_path, encoding):\n",
    "    word_counter = Counter()\n",
    "\n",
    "    with open(file_path, 'r', encoding=encoding) as file:\n",
    "        for line in file:\n",
    "            parts = line.split()\n",
    "            if len(parts) >= 2:\n",
    "                word = parts[1]\n",
    "                count = int(parts[0]) \n",
    "                word_counter[word.strip()] = count\n",
    "\n",
    "    return word_counter\n",
    "\n",
    "\n",
    "def build_unigram_model(word_counter):\n",
    "    unigram_model = {}\n",
    "\n",
    "    total_words = sum(word_counter.values())\n",
    "    \n",
    "\n",
    "\n",
    "    for word, count in word_counter.items():\n",
    "        probability = count / total_words\n",
    "\n",
    "        unigram_model[word] = probability\n",
    "\n",
    "    return unigram_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.3 Check data quality\n",
    "Make sure Python is reading the lines correctly. And it does!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1000 rows in the file. There should be 1000. Correct number? True\n",
      "Encoding : utf-8\n",
      "There are 201315 rows in the file. There should be 201 315. Correct number? True\n"
     ]
    }
   ],
   "source": [
    "# Check ypos\n",
    "typos_file = open(DATA_PATH + r\"\\typo-0.2.txt\")\n",
    "\n",
    "for i, row in enumerate(typos_file):\n",
    "    #print(row)\n",
    "    pass\n",
    "\n",
    "print(f\"There are {i+1} rows in the file. There should be 1000. Correct number? {i+1==1000}\")\n",
    "\n",
    "# Check vocabulary\n",
    "\n",
    "encoding = detect_encoding(DATA_PATH + r\"\\voc-1bwc.txt\") #check encoding\n",
    "print(f\"Encoding : {encoding}\")\n",
    "\n",
    "voc = open(DATA_PATH + r\"\\voc-1bwc.txt\", encoding=encoding)\n",
    "\n",
    "for i, row in enumerate(voc):\n",
    "    #print(row)\n",
    "    pass\n",
    "\n",
    "print(f\"There are {i+1} rows in the file. There should be 201 315. Correct number? {i+1==201315}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many words in the vocabulary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201315\n"
     ]
    }
   ],
   "source": [
    "vocab = get_word_counter(DATA_PATH + r\"\\voc-1bwc.txt\", encoding)\n",
    "print(len(vocab)) # just to verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41223601"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[\"the\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_model = build_unigram_model(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07755452743807591"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_model[\"the\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Implementing various distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Generic Distance function\n",
    "\n",
    "Works with any function that takes two words as an input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This function applies a generic function over an entire vocabulary to compare the distance between a given word\n",
    "and every word inside the vocabulary. It then returns the n_neighbors most similar words.\n",
    "\n",
    "Parameters:\n",
    "    word: The word to find neighbors to.\n",
    "    vocabulary: A list (or list-like) of the vocabulary.\n",
    "    func: The distance function to apply without arguments (without parentheses).\n",
    "    minimum: Do we want the minimum distance? Boolean. True by default, will yield the minimum distance. If False, the function will yield the maximum distance. \n",
    "    n_neighbors: The number of most similar words to return.\n",
    "\n",
    "Returns:\n",
    "    vocabulary.head: A dataframe containing the n_neighbors most similar words to the input word, with the distances. \n",
    "'''\n",
    "def generic_distance_correction(word, vocabulary, func, minimum = True, n_neighbors=1):\n",
    "    vocabulary = pd.DataFrame(vocabulary, columns=[\"words\"])\n",
    "\n",
    "    def calculateDistance(series_word):\n",
    "        return func(series_word, word)\n",
    "    \n",
    "    distances = vocabulary[\"words\"].apply(calculateDistance)\n",
    "    \n",
    "    vocabulary[\"distance\"] = distances\n",
    "\n",
    "    if minimum:\n",
    "        vocabulary = vocabulary.sort_values(\"distance\", ascending=True)\n",
    "    else: \n",
    "        vocabulary = vocabulary.sort_values(\"distance\", ascending=False)\n",
    "\n",
    "    return vocabulary.head(n_neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Testing the correction methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>171215</th>\n",
       "      <td>sperling</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177635</th>\n",
       "      <td>spewing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189762</th>\n",
       "      <td>spelling</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131284</th>\n",
       "      <td>pelling</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180918</th>\n",
       "      <td>sewing</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           words  distance\n",
       "171215  sperling         1\n",
       "177635   spewing         1\n",
       "189762  spelling         1\n",
       "131284   pelling         2\n",
       "180918    sewing         2"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generic_distance_correction('speling', vocab.keys(), editdistance.eval, True, 5) #Edit distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>189762</th>\n",
       "      <td>spelling</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171215</th>\n",
       "      <td>sperling</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167278</th>\n",
       "      <td>spellings</td>\n",
       "      <td>0.925926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196330</th>\n",
       "      <td>sleeping</td>\n",
       "      <td>0.910714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200045</th>\n",
       "      <td>selling</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            words  distance\n",
       "189762   spelling  0.958333\n",
       "171215   sperling  0.958333\n",
       "167278  spellings  0.925926\n",
       "196330   sleeping  0.910714\n",
       "200045    selling  0.904762"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generic_distance_correction('speling', vocab.keys(), jellyfish.jaro_similarity, False, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>189762</th>\n",
       "      <td>spelling</td>\n",
       "      <td>0.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171215</th>\n",
       "      <td>sperling</td>\n",
       "      <td>0.970833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167278</th>\n",
       "      <td>spellings</td>\n",
       "      <td>0.955556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177635</th>\n",
       "      <td>spewing</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196330</th>\n",
       "      <td>sleeping</td>\n",
       "      <td>0.919643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            words  distance\n",
       "189762   spelling  0.975000\n",
       "171215   sperling  0.970833\n",
       "167278  spellings  0.955556\n",
       "177635    spewing  0.933333\n",
       "196330   sleeping  0.919643"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generic_distance_correction('speling', vocab.keys(), jellyfish.jaro_winkler_similarity, False, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Running the correction methods on the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 - Get the typos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Typo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3173</th>\n",
       "      <td>defy</td>\n",
       "      <td>deefy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3174</th>\n",
       "      <td>translation</td>\n",
       "      <td>translatmion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3175</th>\n",
       "      <td>to</td>\n",
       "      <td>tho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3176</th>\n",
       "      <td>But</td>\n",
       "      <td>ut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3177</th>\n",
       "      <td>in</td>\n",
       "      <td>ini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3178</th>\n",
       "      <td>keep</td>\n",
       "      <td>kpeep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3179</th>\n",
       "      <td>game</td>\n",
       "      <td>gme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3180</th>\n",
       "      <td>winds</td>\n",
       "      <td>wantagh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3181</th>\n",
       "      <td>this</td>\n",
       "      <td>tsi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3182</th>\n",
       "      <td>of</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Word          Typo\n",
       "3173         defy         deefy\n",
       "3174  translation  translatmion\n",
       "3175           to           tho\n",
       "3176          But            ut\n",
       "3177           in           ini\n",
       "3178         keep         kpeep\n",
       "3179         game           gme\n",
       "3180        winds       wantagh\n",
       "3181         this           tsi\n",
       "3182           of             o"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(DATA_PATH + r\"\\typo-0.2.txt\", \"r\", encoding=encoding) as file:\n",
    "    text = file.read()\n",
    "\n",
    "\n",
    "typo_pattern = r'<typo orig=\"([^\"]+)\">([^<]+)</typo>'\n",
    "\n",
    "\n",
    "typos = re.findall(typo_pattern, text)\n",
    "\n",
    "\n",
    "typos = pd.DataFrame(typos, columns=[\"Word\", \"Typo\"])\n",
    "\n",
    "\n",
    "typos.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 - Apply correction methods: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correction_df(path, typos, func, minimum = True, n_neighbors=1):\n",
    "\n",
    "    if os.path.isfile(path):\n",
    "        final_df = pd.read_csv(path, index_col = 0)\n",
    "\n",
    "    else: \n",
    "        \n",
    "        final_df = typos.copy()\n",
    "        rows = pd.DataFrame() \n",
    "\n",
    "\n",
    "        for i, typo in tqdm(enumerate(typos[\"Typo\"].tolist()), desc=\"Correcting Typos\", total=len(typos)):\n",
    "            \n",
    "            \n",
    "            \n",
    "            corrections = generic_distance_correction(typo, vocab.keys(), func, minimum, n_neighbors)\n",
    "            new_row = corrections.transpose().reset_index(drop=True)\n",
    "            \n",
    "            #print(new_row)\n",
    "            \n",
    "            new_row.columns = [str(i) for i in range(len(new_row.columns))]\n",
    "            \n",
    "            #print(new_row)\n",
    "            \n",
    "            new_row = pd.concat([new_row.iloc[0], new_row.iloc[1]], axis=0).reset_index(drop=True)\n",
    "            \n",
    "            #print(new_row)\n",
    "            \n",
    "            new_row = pd.DataFrame(new_row.values.flatten()).T\n",
    "            \n",
    "            #print(new_row)\n",
    "            \n",
    "\n",
    "            \n",
    "            #print(new_row)\n",
    "            \n",
    "            row = pd.DataFrame()\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            for col in new_row.columns:\n",
    "                \n",
    "                if int(col) > 4 : row[f\"distance {col-n_neighbors}\"] = new_row[col]\n",
    "                    \n",
    "                else: row[f\"correction {col}\"] = new_row[col]\n",
    "            \n",
    "            \n",
    "                \n",
    "            rows = pd.concat([rows, row], axis=0).reset_index(drop=True)\n",
    "            \n",
    "        \n",
    "      \n",
    "        \n",
    "        final_df = pd.concat([final_df, rows], axis=1)\n",
    "            \n",
    "        #print(final_df)\n",
    "        \n",
    "\n",
    "        final_df.to_csv(path)\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Jaro**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Typo</th>\n",
       "      <th>correction 0</th>\n",
       "      <th>correction 1</th>\n",
       "      <th>correction 2</th>\n",
       "      <th>correction 3</th>\n",
       "      <th>correction 4</th>\n",
       "      <th>distance 0</th>\n",
       "      <th>distance 1</th>\n",
       "      <th>distance 2</th>\n",
       "      <th>distance 3</th>\n",
       "      <th>distance 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wealthy</td>\n",
       "      <td>wealtohy</td>\n",
       "      <td>wealthy</td>\n",
       "      <td>wealth</td>\n",
       "      <td>welty</td>\n",
       "      <td>healthy</td>\n",
       "      <td>watley</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.861111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>afford</td>\n",
       "      <td>aford</td>\n",
       "      <td>axford</td>\n",
       "      <td>afford</td>\n",
       "      <td>alford</td>\n",
       "      <td>ford</td>\n",
       "      <td>walford</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Catholic</td>\n",
       "      <td>CatholiaCtholic</td>\n",
       "      <td>athol</td>\n",
       "      <td>pathological</td>\n",
       "      <td>palaeolithic</td>\n",
       "      <td>alghaithi</td>\n",
       "      <td>holi</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.765741</td>\n",
       "      <td>0.755556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cousins</td>\n",
       "      <td>coxusins</td>\n",
       "      <td>cousins</td>\n",
       "      <td>cousin</td>\n",
       "      <td>compulsions</td>\n",
       "      <td>coxswain</td>\n",
       "      <td>cushions</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.837121</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>masks</td>\n",
       "      <td>mmasks</td>\n",
       "      <td>masks</td>\n",
       "      <td>asks</td>\n",
       "      <td>mass</td>\n",
       "      <td>mask</td>\n",
       "      <td>unmasks</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.849206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3178</th>\n",
       "      <td>keep</td>\n",
       "      <td>kpeep</td>\n",
       "      <td>keep</td>\n",
       "      <td>peep</td>\n",
       "      <td>upkeep</td>\n",
       "      <td>pee</td>\n",
       "      <td>kee</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.877778</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3179</th>\n",
       "      <td>game</td>\n",
       "      <td>gme</td>\n",
       "      <td>gme</td>\n",
       "      <td>gmes</td>\n",
       "      <td>gome</td>\n",
       "      <td>game</td>\n",
       "      <td>gamez</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3180</th>\n",
       "      <td>winds</td>\n",
       "      <td>wantagh</td>\n",
       "      <td>wantagh</td>\n",
       "      <td>wantage</td>\n",
       "      <td>wana</td>\n",
       "      <td>want</td>\n",
       "      <td>wang</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3181</th>\n",
       "      <td>this</td>\n",
       "      <td>tsi</td>\n",
       "      <td>tsi</td>\n",
       "      <td>utsi</td>\n",
       "      <td>tfsi</td>\n",
       "      <td>thsi</td>\n",
       "      <td>etsi</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3182</th>\n",
       "      <td>of</td>\n",
       "      <td>o</td>\n",
       "      <td>olb</td>\n",
       "      <td>ori</td>\n",
       "      <td>oly</td>\n",
       "      <td>osc</td>\n",
       "      <td>olg</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3183 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word             Typo correction 0  correction 1  correction 2  \\\n",
       "0      wealthy         wealtohy      wealthy        wealth         welty   \n",
       "1       afford            aford       axford        afford        alford   \n",
       "2     Catholic  CatholiaCtholic        athol  pathological  palaeolithic   \n",
       "3      cousins         coxusins      cousins        cousin   compulsions   \n",
       "4        masks           mmasks        masks          asks          mass   \n",
       "...        ...              ...          ...           ...           ...   \n",
       "3178      keep            kpeep         keep          peep        upkeep   \n",
       "3179      game              gme          gme          gmes          gome   \n",
       "3180     winds          wantagh      wantagh       wantage          wana   \n",
       "3181      this              tsi          tsi          utsi          tfsi   \n",
       "3182        of                o          olb           ori           oly   \n",
       "\n",
       "     correction 3 correction 4  distance 0  distance 1  distance 2  \\\n",
       "0         healthy       watley    0.958333    0.916667    0.875000   \n",
       "1            ford      walford    0.944444    0.944444    0.944444   \n",
       "2       alghaithi         holi    0.777778    0.766667    0.766667   \n",
       "3        coxswain     cushions    0.958333    0.916667    0.837121   \n",
       "4            mask      unmasks    0.944444    0.888889    0.888889   \n",
       "...           ...          ...         ...         ...         ...   \n",
       "3178          pee          kee    0.933333    0.933333    0.877778   \n",
       "3179         game        gamez    1.000000    0.916667    0.916667   \n",
       "3180         want         wang    1.000000    0.904762    0.857143   \n",
       "3181         thsi         etsi    1.000000    0.916667    0.916667   \n",
       "3182          osc          olg    0.777778    0.777778    0.777778   \n",
       "\n",
       "      distance 3  distance 4  \n",
       "0       0.869048    0.861111  \n",
       "1       0.933333    0.904762  \n",
       "2       0.765741    0.755556  \n",
       "3       0.833333    0.833333  \n",
       "4       0.888889    0.849206  \n",
       "...          ...         ...  \n",
       "3178    0.866667    0.866667  \n",
       "3179    0.916667    0.866667  \n",
       "3180    0.857143    0.857143  \n",
       "3181    0.916667    0.916667  \n",
       "3182    0.777778    0.777778  \n",
       "\n",
       "[3183 rows x 12 columns]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaro_correction_df = get_correction_df(DATA_PATH + \"\\jaro_correction_df.csv\", typos, jellyfish.jaro_similarity, False, 5)\n",
    "jaro_correction_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jaro-Winkler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Correcting Typos: 100%|████████████████████████████████████████████████████████████| 3183/3183 [14:52<00:00,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  correction 0  correction 1  correction 2 correction 3 correction 4  \\\n",
      "0      wealthy        wealth         welty         weal     wealthtv   \n",
      "1       afford        alford        axford         ford      affords   \n",
      "2        athol  pathological  palaeolithic    alghaithi         holi   \n",
      "3      cousins        cousin      coxswain  compulsions     cosiness   \n",
      "4        masks          mask          mass         asks          mma   \n",
      "\n",
      "  distance 0 distance 1 distance 2 distance 3 distance 4  \n",
      "0      0.975       0.95        0.9        0.9        0.9  \n",
      "1   0.955556       0.95       0.95   0.933333    0.92381  \n",
      "2   0.777778   0.766667   0.766667   0.765741   0.755556  \n",
      "3   0.966667   0.933333   0.883333   0.869697   0.866667  \n",
      "4       0.95        0.9        0.9   0.888889   0.883333  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Typo</th>\n",
       "      <th>correction 0</th>\n",
       "      <th>correction 1</th>\n",
       "      <th>correction 2</th>\n",
       "      <th>correction 3</th>\n",
       "      <th>correction 4</th>\n",
       "      <th>distance 0</th>\n",
       "      <th>distance 1</th>\n",
       "      <th>distance 2</th>\n",
       "      <th>distance 3</th>\n",
       "      <th>distance 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wealthy</td>\n",
       "      <td>wealtohy</td>\n",
       "      <td>wealthy</td>\n",
       "      <td>wealth</td>\n",
       "      <td>welty</td>\n",
       "      <td>weal</td>\n",
       "      <td>wealthtv</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>afford</td>\n",
       "      <td>aford</td>\n",
       "      <td>afford</td>\n",
       "      <td>alford</td>\n",
       "      <td>axford</td>\n",
       "      <td>ford</td>\n",
       "      <td>affords</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.92381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Catholic</td>\n",
       "      <td>CatholiaCtholic</td>\n",
       "      <td>athol</td>\n",
       "      <td>pathological</td>\n",
       "      <td>palaeolithic</td>\n",
       "      <td>alghaithi</td>\n",
       "      <td>holi</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.765741</td>\n",
       "      <td>0.755556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cousins</td>\n",
       "      <td>coxusins</td>\n",
       "      <td>cousins</td>\n",
       "      <td>cousin</td>\n",
       "      <td>coxswain</td>\n",
       "      <td>compulsions</td>\n",
       "      <td>cosiness</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.869697</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>masks</td>\n",
       "      <td>mmasks</td>\n",
       "      <td>masks</td>\n",
       "      <td>mask</td>\n",
       "      <td>mass</td>\n",
       "      <td>asks</td>\n",
       "      <td>mma</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.883333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3178</th>\n",
       "      <td>keep</td>\n",
       "      <td>kpeep</td>\n",
       "      <td>keep</td>\n",
       "      <td>peep</td>\n",
       "      <td>kpe</td>\n",
       "      <td>kee</td>\n",
       "      <td>keeps</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.906667</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3179</th>\n",
       "      <td>game</td>\n",
       "      <td>gme</td>\n",
       "      <td>gme</td>\n",
       "      <td>gmes</td>\n",
       "      <td>game</td>\n",
       "      <td>gome</td>\n",
       "      <td>gomez</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3180</th>\n",
       "      <td>winds</td>\n",
       "      <td>wantagh</td>\n",
       "      <td>wantagh</td>\n",
       "      <td>wantage</td>\n",
       "      <td>want</td>\n",
       "      <td>wana</td>\n",
       "      <td>wang</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3181</th>\n",
       "      <td>this</td>\n",
       "      <td>tsi</td>\n",
       "      <td>tsi</td>\n",
       "      <td>tsim</td>\n",
       "      <td>tsoi</td>\n",
       "      <td>tsai</td>\n",
       "      <td>tsui</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3182</th>\n",
       "      <td>of</td>\n",
       "      <td>o</td>\n",
       "      <td>osk</td>\n",
       "      <td>okd</td>\n",
       "      <td>ote</td>\n",
       "      <td>oia</td>\n",
       "      <td>oro</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3183 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word             Typo correction 0  correction 1  correction 2  \\\n",
       "0      wealthy         wealtohy      wealthy        wealth         welty   \n",
       "1       afford            aford       afford        alford        axford   \n",
       "2     Catholic  CatholiaCtholic        athol  pathological  palaeolithic   \n",
       "3      cousins         coxusins      cousins        cousin      coxswain   \n",
       "4        masks           mmasks        masks          mask          mass   \n",
       "...        ...              ...          ...           ...           ...   \n",
       "3178      keep            kpeep         keep          peep           kpe   \n",
       "3179      game              gme          gme          gmes          game   \n",
       "3180     winds          wantagh      wantagh       wantage          want   \n",
       "3181      this              tsi          tsi          tsim          tsoi   \n",
       "3182        of                o          osk           okd           ote   \n",
       "\n",
       "     correction 3 correction 4 distance 0 distance 1 distance 2 distance 3  \\\n",
       "0            weal     wealthtv      0.975       0.95        0.9        0.9   \n",
       "1            ford      affords   0.955556       0.95       0.95   0.933333   \n",
       "2       alghaithi         holi   0.777778   0.766667   0.766667   0.765741   \n",
       "3     compulsions     cosiness   0.966667   0.933333   0.883333   0.869697   \n",
       "4            asks          mma       0.95        0.9        0.9   0.888889   \n",
       "...           ...          ...        ...        ...        ...        ...   \n",
       "3178          kee        keeps       0.94   0.933333   0.906667       0.88   \n",
       "3179         gome        gomez        1.0   0.941667      0.925      0.925   \n",
       "3180         wana         wang        1.0   0.942857   0.914286        0.9   \n",
       "3181         tsai         tsui        1.0   0.941667   0.933333   0.933333   \n",
       "3182          oia          oro        0.8        0.8        0.8        0.8   \n",
       "\n",
       "     distance 4  \n",
       "0           0.9  \n",
       "1       0.92381  \n",
       "2      0.755556  \n",
       "3      0.866667  \n",
       "4      0.883333  \n",
       "...         ...  \n",
       "3178       0.88  \n",
       "3179       0.88  \n",
       "3180        0.9  \n",
       "3181   0.933333  \n",
       "3182        0.8  \n",
       "\n",
       "[3183 rows x 12 columns]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jw_correction_df = get_correction_df(DATA_PATH + \"\\jw_correction_df.csv\", typos, jellyfish.jaro_winkler_similarity, False, 5)\n",
    "jw_correction_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Edit Distance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Correcting Typos: 100%|████████████████████████████████████████████████████████████| 3183/3183 [34:41<00:00,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     correction 0     correction 1 correction 2 correction 3 correction 4  \\\n",
      "0         wealthy           wealth      healthy     wealthtv       fealty   \n",
      "1          afford           alford         ford        afore       axford   \n",
      "2  anglo-catholic  catholic-muslim   pathologic  paleolithic   shopaholic   \n",
      "3         cousins           cousin      coupons     housings      coggins   \n",
      "4           masks            basks       flasks         maks       smacks   \n",
      "\n",
      "  distance 0 distance 1 distance 2 distance 3 distance 4  \n",
      "0          1          2          2          3          3  \n",
      "1          1          1          1          1          1  \n",
      "2          7          7          7          7          7  \n",
      "3          1          2          3          3          3  \n",
      "4          1          2          2          2          2  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Typo</th>\n",
       "      <th>correction 0</th>\n",
       "      <th>correction 1</th>\n",
       "      <th>correction 2</th>\n",
       "      <th>correction 3</th>\n",
       "      <th>correction 4</th>\n",
       "      <th>distance 0</th>\n",
       "      <th>distance 1</th>\n",
       "      <th>distance 2</th>\n",
       "      <th>distance 3</th>\n",
       "      <th>distance 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wealthy</td>\n",
       "      <td>wealtohy</td>\n",
       "      <td>wealthy</td>\n",
       "      <td>wealth</td>\n",
       "      <td>healthy</td>\n",
       "      <td>wealthtv</td>\n",
       "      <td>fealty</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>afford</td>\n",
       "      <td>aford</td>\n",
       "      <td>afford</td>\n",
       "      <td>alford</td>\n",
       "      <td>ford</td>\n",
       "      <td>afore</td>\n",
       "      <td>axford</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Catholic</td>\n",
       "      <td>CatholiaCtholic</td>\n",
       "      <td>anglo-catholic</td>\n",
       "      <td>catholic-muslim</td>\n",
       "      <td>pathologic</td>\n",
       "      <td>paleolithic</td>\n",
       "      <td>shopaholic</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cousins</td>\n",
       "      <td>coxusins</td>\n",
       "      <td>cousins</td>\n",
       "      <td>cousin</td>\n",
       "      <td>coupons</td>\n",
       "      <td>housings</td>\n",
       "      <td>coggins</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>masks</td>\n",
       "      <td>mmasks</td>\n",
       "      <td>masks</td>\n",
       "      <td>basks</td>\n",
       "      <td>flasks</td>\n",
       "      <td>maks</td>\n",
       "      <td>smacks</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3178</th>\n",
       "      <td>keep</td>\n",
       "      <td>kpeep</td>\n",
       "      <td>peep</td>\n",
       "      <td>keep</td>\n",
       "      <td>peed</td>\n",
       "      <td>peeps</td>\n",
       "      <td>keeps</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3179</th>\n",
       "      <td>game</td>\n",
       "      <td>gme</td>\n",
       "      <td>gme</td>\n",
       "      <td>gmb</td>\n",
       "      <td>gmh</td>\n",
       "      <td>fme</td>\n",
       "      <td>gmd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3180</th>\n",
       "      <td>winds</td>\n",
       "      <td>wantagh</td>\n",
       "      <td>wantagh</td>\n",
       "      <td>wantage</td>\n",
       "      <td>wattage</td>\n",
       "      <td>wastage</td>\n",
       "      <td>vantage</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3181</th>\n",
       "      <td>this</td>\n",
       "      <td>tsi</td>\n",
       "      <td>tsi</td>\n",
       "      <td>asi</td>\n",
       "      <td>rsi</td>\n",
       "      <td>tfi</td>\n",
       "      <td>atsi</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3182</th>\n",
       "      <td>of</td>\n",
       "      <td>o</td>\n",
       "      <td>joa</td>\n",
       "      <td>okc</td>\n",
       "      <td>ols</td>\n",
       "      <td>ope</td>\n",
       "      <td>opv</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3183 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word             Typo    correction 0     correction 1 correction 2  \\\n",
       "0      wealthy         wealtohy         wealthy           wealth      healthy   \n",
       "1       afford            aford          afford           alford         ford   \n",
       "2     Catholic  CatholiaCtholic  anglo-catholic  catholic-muslim   pathologic   \n",
       "3      cousins         coxusins         cousins           cousin      coupons   \n",
       "4        masks           mmasks           masks            basks       flasks   \n",
       "...        ...              ...             ...              ...          ...   \n",
       "3178      keep            kpeep            peep             keep         peed   \n",
       "3179      game              gme             gme              gmb          gmh   \n",
       "3180     winds          wantagh         wantagh          wantage      wattage   \n",
       "3181      this              tsi             tsi              asi          rsi   \n",
       "3182        of                o             joa              okc          ols   \n",
       "\n",
       "     correction 3 correction 4 distance 0 distance 1 distance 2 distance 3  \\\n",
       "0        wealthtv       fealty          1          2          2          3   \n",
       "1           afore       axford          1          1          1          1   \n",
       "2     paleolithic   shopaholic          7          7          7          7   \n",
       "3        housings      coggins          1          2          3          3   \n",
       "4            maks       smacks          1          2          2          2   \n",
       "...           ...          ...        ...        ...        ...        ...   \n",
       "3178        peeps        keeps          1          1          2          2   \n",
       "3179          fme          gmd          0          1          1          1   \n",
       "3180      wastage      vantage          0          1          2          2   \n",
       "3181          tfi         atsi          0          1          1          1   \n",
       "3182          ope          opv          2          2          2          2   \n",
       "\n",
       "     distance 4  \n",
       "0             3  \n",
       "1             1  \n",
       "2             7  \n",
       "3             3  \n",
       "4             2  \n",
       "...         ...  \n",
       "3178          2  \n",
       "3179          1  \n",
       "3180          2  \n",
       "3181          1  \n",
       "3182          2  \n",
       "\n",
       "[3183 rows x 12 columns]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed_correction_df = get_correction_df(DATA_PATH + \"\\ed_correction_df.csv\", typos, editdistance.eval, True, 5)\n",
    "ed_correction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Return the text file with the corrections \n",
    "\n",
    "### 1.4.1 Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_correction(typo_row):\n",
    "    name = typo_row[\"Word\"]\n",
    "    typo = typo_row['Typo']\n",
    "    \n",
    "    #print(typo_row)\n",
    "    \n",
    "    neigh0 = typo_row[\"correction 0\"]\n",
    "    neigh1 = typo_row[\"correction 1\"]\n",
    "    neigh2 = typo_row[\"correction 2\"]\n",
    "    neigh3 = typo_row[\"correction 3\"]\n",
    "    neigh4 = typo_row[\"correction 4\"]\n",
    "    return f\"<correction orig=\\\"{name}\\\" typo=\\\"{typo}\\\">{neigh0} {neigh1} {neigh2} {neigh3} {neigh4}</correction>\"\n",
    "\n",
    "def format_typo(typo_row):\n",
    "    orig = typo_row[\"Word\"]\n",
    "    typo = typo_row['Typo']\n",
    "    return f'<typo orig=\"{orig}\">{typo}</typo>'\n",
    "\n",
    "def replace_typos(path, typo_df, typos_str): \n",
    " \n",
    "    formatted_corr = typo_df.apply(format_correction, axis=1)\n",
    "    formatted_typo = typo_df.apply(format_typo, axis=1)\n",
    "\n",
    "    formatted_dict = dict(zip(formatted_typo, formatted_corr))\n",
    "\n",
    "    # Erase the contents of the file if it already exists\n",
    "    if os.path.isfile(path):\n",
    "        os.remove(path)\n",
    "\n",
    "    for typo_pattern in formatted_dict.keys():\n",
    "        correction_pattern = formatted_dict[typo_pattern]\n",
    "        typos_str = re.sub(typo_pattern, correction_pattern, typos_str)\n",
    "\n",
    "    # Write it to a .txt file\n",
    "    with open(path, \"a\") as out_file:\n",
    "        out_file.write(typos_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.2 Replace typos for all distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "typos_file = open(DATA_PATH + r\"\\typo-0.2.txt\").read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jaro**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_typos(DATA_PATH + \"\\jaro_corrections-0.2.txt\", jaro_correction_df, typos_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jaro-Winkler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_typos(DATA_PATH + \"\\jw_corrections-0.2.txt\", jw_correction_df, typos_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Edit Distance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_typos(DATA_PATH + \"\\ed_corrections-0.2.txt\", ed_correction_df, typos_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create evaluation metrics\n",
    "Here's a couple of ideas:\n",
    "\n",
    "- *Hard* accuracy: Does the first word match the original word?\n",
    "- *Soft* accuracy: Is the original word in one of the neighbors? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_correction(path):\n",
    "    corrected_file = open(path).read()\n",
    "    correction_pattern = r'<correction.*?</correction>'\n",
    "    matches = re.findall(correction_pattern, corrected_file)\n",
    "\n",
    "    hardacc = []\n",
    "    softacc = []\n",
    "    extraction_pattern = '<correction orig=\"|\" typo=\"|\">|</correction>'\n",
    "    for correction in matches: \n",
    "        subbed_corr = re.sub(extraction_pattern, \" \", correction) # Remove all the fluff\n",
    "        extracted_words = subbed_corr.split(\" \")[1:-1] # remove the frst and last splits, which will always be empty\n",
    "\n",
    "        original = extracted_words[0] \n",
    "        corrected = extracted_words[2:]\n",
    "\n",
    "        hardacc.append(original == corrected[0])\n",
    "        softacc.append(original in corrected)\n",
    "\n",
    "    hard_accuracy = sum(hardacc) / len(hardacc)\n",
    "    soft_accuracy = sum(softacc) / len(softacc)\n",
    "\n",
    "    print(f\"Hard accuracy: {round(hard_accuracy, 2)}\\nSoft accuracy: {round(soft_accuracy, 2)}\")\n",
    "        \n",
    "    return hard_accuracy, soft_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard accuracy: 0.23\n",
      "Soft accuracy: 0.38\n"
     ]
    }
   ],
   "source": [
    "corr_path = DATA_PATH + r\"\\ed_corrections-0.2.txt\"\n",
    "hard, soft = evaluate_correction(corr_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
