{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import chardet\n",
    "import codecs\n",
    "import jellyfish\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "#DATA_PATH = r\"C:\\Users\\Louis\\Documents\\University\\Masters\\A23\\NLP\\Devoirs\\data\\hw2\"\n",
    "DATA_PATH = r\"C:\\Users\\barka\\Desktop\\NLP\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get the data\n",
    "Make sure Python is reading the lines correctly. And it does!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1000 rows in the file. There should be 1000. Correct number? True\n"
     ]
    }
   ],
   "source": [
    "typos_file = open(DATA_PATH + r\"\\typo-0.2.txt\")\n",
    "\n",
    "for i, row in enumerate(typos_file):\n",
    "    #print(row)\n",
    "    pass\n",
    "\n",
    "print(f\"There are {i+1} rows in the file. There should be 1000. Correct number? {i+1==1000}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding : utf-8\n"
     ]
    }
   ],
   "source": [
    "def detect_encoding(file_path):\n",
    "    \n",
    "    with open(file_path, 'rb') as file:\n",
    "        rawdata = file.read()\n",
    "    result = chardet.detect(rawdata)\n",
    "    return result['encoding']\n",
    "\n",
    "encoding = detect_encoding(DATA_PATH + r\"\\voc-1bwc.txt\")\n",
    "print(f\"Encoding : {encoding}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 201315 rows in the file. There should be 201 315. Correct number? True\n"
     ]
    }
   ],
   "source": [
    "voc = open(DATA_PATH + r\"\\voc-1bwc.txt\", encoding=encoding)\n",
    "\n",
    "for i, row in enumerate(voc):\n",
    "    #print(row)\n",
    "    pass\n",
    "\n",
    "print(f\"There are {i+1} rows in the file. There should be 201 315. Correct number? {i+1==201315}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201315\n"
     ]
    }
   ],
   "source": [
    "def get_word_counter(file_path, encoding):\n",
    "    \n",
    "    \n",
    "    word_counter = Counter()\n",
    "\n",
    "    \n",
    "    with open(file_path, 'r', encoding=encoding) as file:\n",
    "        for line in file:\n",
    "            \n",
    "            parts = line.split()\n",
    "            if len(parts) >= 2:\n",
    "                word = parts[1]\n",
    "                \n",
    "                word_counter[word.strip()] += 1\n",
    "\n",
    "    # Return the Counter containing word frequencies\n",
    "    return word_counter\n",
    "\n",
    "vocab = get_word_counter(DATA_PATH + r\"\\voc-1bwc.txt\", encoding)\n",
    "print(len(vocab)) # just to verify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. implementing various distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Edit distance (Distance dâ€™edition) taken from the blog :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P(word, N=sum(vocab.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return vocab[word] / N\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in vocab)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Jaro distance :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaro_correction(word):\n",
    "    \n",
    "    max_distance = float('-inf')\n",
    "    max_word = \"\"\n",
    "    \n",
    "    for w in vocab :\n",
    "        \n",
    "        distance = jellyfish.jaro_distance(word, w)\n",
    "        \n",
    "        if max_distance < distance :\n",
    "            \n",
    "            max_distance = distance\n",
    "            max_word = w\n",
    "    \n",
    "    return max_word, max_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Jaro-Winkler distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaro_winkler_correction(word):\n",
    "    \n",
    "    max_distance = float('-inf')\n",
    "    max_word = \"\"\n",
    "    \n",
    "    for w in vocab :\n",
    "        \n",
    "        distance = jellyfish.jaro_winkler(word, w)\n",
    "        \n",
    "        if max_distance < distance :\n",
    "            \n",
    "            max_distance = distance\n",
    "            max_word = w\n",
    "    \n",
    "    return max_word, max_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Testing the correction methods on the same word :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spelling'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction('speling') #Edit distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sperling', 0.9583333333333334)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaro_correction('speling') #Jaro distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('spelling', 0.975)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaro_winkler_correction('speling') #Jaro-Winkler distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Running the correction methods on the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the typos (test):  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"\"\"\n",
    "Doesn 't this just hit the very <typo orig=\"wealthy\">wealtohy</typo> who can <typo orig=\"afford\">aford</typo> it ?\n",
    "Also , <typo orig=\"Catholic\">CatholiaCtholic</typo> school girl outfits .\n",
    "He wrestled his <typo orig=\"cousins\">coxusins</typo> wearing funny <typo orig=\"masks\">mmasks</typo> worn by the locals .\n",
    "Chrysler is in the process of seeking approval from a U.S. Bankruptcy Court judge to sell itself <typo orig=\"to\">tos</typo> a new entity jointly owned <typo orig=\"by\">b</typo> Fiat , the United Auto <typo orig=\"Workers\">rokers</typo> and <typo orig=\"the\">tthe</typo> U.S. and Canadian <typo orig=\"governments\">government</typo> .\n",
    "\"\"\"\n",
    "\n",
    "typo_pattern = r'<typo orig=\"([^\"]+)\">([^<]+)</typo>'\n",
    "\n",
    "\n",
    "typos = re.findall(typo_pattern, text)\n",
    "\n",
    "typos = dict(typos)\n",
    "\n",
    "\n",
    "for orig, typo in typos.items():\n",
    "    #print(\"Original:\", orig)\n",
    "    #print(\"Typo:\", typo)\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the typos (data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_PATH + r\"\\typo-0.2.txt\", \"r\", encoding=encoding) as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "typos = re.findall(typo_pattern, text)\n",
    "\n",
    "typos = dict(typos)\n",
    "\n",
    "\n",
    "for orig, typo in typos.items():\n",
    "    #print(\"Original:\", orig)\n",
    "    #print(\"Typo:\", typo)\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('wealthy', 'wealtohy')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(typos.items())[:1][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Apply correction methods: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Correcting Typos: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1601/1601 [14:18<00:00,  1.87it/s]\n"
     ]
    }
   ],
   "source": [
    "corrected_typos = dict()\n",
    "\n",
    "for orig, typo in tqdm(typos.items(), desc=\"Correcting Typos\"):\n",
    "    \n",
    "    correction = jaro_winkler_correction(typo)[0]  # Jaro-Winkler distance\n",
    "    corrected_typos[orig] = correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of corrected typos : 1601\n",
      " Number of typos : 1601\n"
     ]
    }
   ],
   "source": [
    "print(f\" Number of corrected typos : {len(corrected_typos)}\")\n",
    "print(f\" Number of typos : {len(typos)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return the text file with the corrections : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO (if u want and u have time u can write otherwise i will do it later at night)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
